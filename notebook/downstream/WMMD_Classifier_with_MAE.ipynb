{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T09:52:45.835580Z",
     "start_time": "2025-07-08T09:52:45.828303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T09:53:02.512830Z",
     "start_time": "2025-07-08T09:52:48.318858Z"
    }
   },
   "cell_type": "code",
   "source": "from scripts.pretrain_script import *",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\s3prl\\upstream\\byol_s\\byol_a\\common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "ESPnet is not installed, cannot use espnet_hubert upstream\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1017 examples, 31 classes\n",
      "  Clymene_Dolphin: 38\n",
      "  Bottlenose_Dolphin: 15\n",
      "  Spinner_Dolphin: 69\n",
      "  Beluga,_White_Whale: 30\n",
      "  Bearded_Seal: 22\n",
      "  Minke_Whale: 10\n",
      "  Humpback_Whale: 38\n",
      "  Southern_Right_Whale: 15\n",
      "  White-sided_Dolphin: 33\n",
      "  Narwhal: 30\n",
      "  White-beaked_Dolphin: 34\n",
      "  Northern_Right_Whale: 32\n",
      "  Frasers_Dolphin: 52\n",
      "  Grampus,_Rissos_Dolphin: 40\n",
      "  Harp_Seal: 28\n",
      "  Atlantic_Spotted_Dolphin: 35\n",
      "  Fin,_Finback_Whale: 30\n",
      "  Ross_Seal: 30\n",
      "  Rough-Toothed_Dolphin: 30\n",
      "  Killer_Whale: 21\n",
      "  Pantropical_Spotted_Dolphin: 40\n",
      "  Short-Finned_Pacific_Pilot_Whale: 40\n",
      "  Bowhead_Whale: 36\n",
      "  False_Killer_Whale: 35\n",
      "  Melon_Headed_Whale: 38\n",
      "  Long-Finned_Pilot_Whale: 42\n",
      "  Striped_Dolphin: 49\n",
      "  Leopard_Seal: 6\n",
      "  Walrus: 23\n",
      "  Sperm_Whale: 45\n",
      "  Common_Dolphin: 31\n",
      "Validation dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 12\n",
      "  Bottlenose_Dolphin: 5\n",
      "  Spinner_Dolphin: 23\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 7\n",
      "  Minke_Whale: 4\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 11\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 18\n",
      "  Grampus,_Rissos_Dolphin: 13\n",
      "  Harp_Seal: 9\n",
      "  Atlantic_Spotted_Dolphin: 12\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 13\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 13\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 8\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 10\n",
      "Test dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 13\n",
      "  Bottlenose_Dolphin: 4\n",
      "  Spinner_Dolphin: 22\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 8\n",
      "  Minke_Whale: 3\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 12\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 17\n",
      "  Grampus,_Rissos_Dolphin: 14\n",
      "  Harp_Seal: 10\n",
      "  Atlantic_Spotted_Dolphin: 11\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 14\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 12\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 7\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 11\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T09:53:03.454557Z",
     "start_time": "2025-07-08T09:53:02.530475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sanity check\n",
    "model = WMMDClassifier(\n",
    " num_classes=31,\n",
    " backbone=\"patrickvonplaten/tiny-wav2vec2-no-tokenizer\", finetune=True,\n",
    " class_weights=class_weights,\n",
    " ckpt_path=\"\"\n",
    ")\n",
    "\n",
    "print(ModelSummary(model, max_depth=1))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | Wav2Vec2Model       | 26.7 K | eval \n",
      "1  | classifier      | Sequential          | 49.2 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "75.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "75.9 K    Total params\n",
      "0.304     Total estimated model params size (MB)\n",
      "16        Modules in train mode\n",
      "88        Modules in eval mode\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T09:53:04.575638Z",
     "start_time": "2025-07-08T09:53:03.491020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sanity check\n",
    "model = WMMDClassifier(\n",
    " num_classes=31,\n",
    " backbone_lr=1e-5,\n",
    " head_lr=1e-4,\n",
    " backbone=\"mae-ast\",\n",
    " finetune=True,\n",
    " class_weights=class_weights,\n",
    " ckpt_path=\"notebook/downstream/load_model/random-4en1de.pt\"\n",
    ")\n",
    "\n",
    "print(ModelSummary(model, max_depth=1))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 36.0 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "42.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "42.4 M    Total params\n",
      "169.438   Total estimated model params size (MB)\n",
      "108       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T09:53:04.588022Z",
     "start_time": "2025-07-08T09:53:04.585698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs = [\n",
    "    # {\"num_classes\": num_classes, \"lr\": 1e-3, \"backbone\": \"facebook/wav2vec2-base\",  \"finetune\": False, \"class_weights\": class_weights, \"max_epochs\": 500, \"ckpt_path\": \"\"},\n",
    "    {\"num_classes\": num_classes, \"lr\": 1e-6, \"backbone\": \"mae-ast\",  \"finetune\": True, \"class_weights\": class_weights, \"max_epochs\": 400, \"ckpt_path\": \"random-4en1de.pt\"},\n",
    "    # {\"num_classes\": num_classes, \"lr\": 1e-3, \"backbone\": \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\",  \"finetune\": True, \"class_weights\": class_weights, \"max_epochs\": 500, \"ckpt_path\": \"\"},\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2 Encoders - Random weights (scratch)\n",
    "\n",
    "Starting with same arch. as our pretrained 2 encoder model, just with random weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:24:00.482596Z",
     "start_time": "2025-07-08T10:18:14.246043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_2 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-4,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-2en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_2, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.735   Total estimated model params size (MB)\n",
      "80        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5899705290794373\r\n",
      "         test_f1            0.5231074690818787\r\n",
      "        test_loss           1.3964496850967407\r\n",
      "     test_precision         0.5830875635147095\r\n",
      "       test_recall          0.4931170344352722\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250708_202359/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250708_202359\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Encoders - Pretrained"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_2en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/2en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_2en1de, early_stopping=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4 Encoders - Random weights (scratch)\n",
    "\n",
    "Starting with same arch. as our pretrained 4 encoder model, just with random weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:31:44.469469Z",
     "start_time": "2025-07-08T10:24:00.510412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_4 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-4,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-4en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_4, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 36.0 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "42.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "42.4 M    Total params\n",
      "169.438   Total estimated model params size (MB)\n",
      "108       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.6047197580337524\r\n",
      "         test_f1            0.5329402685165405\r\n",
      "        test_loss           1.4297627210617065\r\n",
      "     test_precision          0.595378577709198\r\n",
      "       test_recall          0.5024582147598267\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250708_203143/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250708_203143\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 Encoders - Pretrained\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_4en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/4en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_4en1de, early_stopping=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6 Encoders - Random weights (scratch)\n",
    "\n",
    "Starting with same arch. as our pretrained 6 encoder model, just with random weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T10:41:22.690875Z",
     "start_time": "2025-07-08T10:31:44.535718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_6 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-4,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-6en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_6, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "56.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "56.5 M    Total params\n",
      "226.141   Total estimated model params size (MB)\n",
      "136       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5280236005783081\r\n",
      "         test_f1            0.4444445073604584\r\n",
      "        test_loss            1.596319556236267\r\n",
      "     test_precision         0.5176990628242493\r\n",
      "       test_recall          0.4085546135902405\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250708_204122/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250708_204122\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6 Encoders - Pretrained"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_6en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/6en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_6en1de, early_stopping=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
