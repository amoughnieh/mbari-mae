{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T22:29:27.263071Z",
     "start_time": "2025-07-09T22:29:27.255679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T22:29:41.134015Z",
     "start_time": "2025-07-09T22:29:27.404433Z"
    }
   },
   "cell_type": "code",
   "source": "from scripts.ft_lp import *",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\s3prl\\upstream\\byol_s\\byol_a\\common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "ESPnet is not installed, cannot use espnet_hubert upstream\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1017 examples, 31 classes\n",
      "  Clymene_Dolphin: 38\n",
      "  Bottlenose_Dolphin: 15\n",
      "  Spinner_Dolphin: 69\n",
      "  Beluga,_White_Whale: 30\n",
      "  Bearded_Seal: 22\n",
      "  Minke_Whale: 10\n",
      "  Humpback_Whale: 38\n",
      "  Southern_Right_Whale: 15\n",
      "  White-sided_Dolphin: 33\n",
      "  Narwhal: 30\n",
      "  White-beaked_Dolphin: 34\n",
      "  Northern_Right_Whale: 32\n",
      "  Frasers_Dolphin: 52\n",
      "  Grampus,_Rissos_Dolphin: 40\n",
      "  Harp_Seal: 28\n",
      "  Atlantic_Spotted_Dolphin: 35\n",
      "  Fin,_Finback_Whale: 30\n",
      "  Ross_Seal: 30\n",
      "  Rough-Toothed_Dolphin: 30\n",
      "  Killer_Whale: 21\n",
      "  Pantropical_Spotted_Dolphin: 40\n",
      "  Short-Finned_Pacific_Pilot_Whale: 40\n",
      "  Bowhead_Whale: 36\n",
      "  False_Killer_Whale: 35\n",
      "  Melon_Headed_Whale: 38\n",
      "  Long-Finned_Pilot_Whale: 42\n",
      "  Striped_Dolphin: 49\n",
      "  Leopard_Seal: 6\n",
      "  Walrus: 23\n",
      "  Sperm_Whale: 45\n",
      "  Common_Dolphin: 31\n",
      "Validation dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 12\n",
      "  Bottlenose_Dolphin: 5\n",
      "  Spinner_Dolphin: 23\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 7\n",
      "  Minke_Whale: 4\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 11\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 18\n",
      "  Grampus,_Rissos_Dolphin: 13\n",
      "  Harp_Seal: 9\n",
      "  Atlantic_Spotted_Dolphin: 12\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 13\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 13\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 8\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 10\n",
      "Test dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 13\n",
      "  Bottlenose_Dolphin: 4\n",
      "  Spinner_Dolphin: 22\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 8\n",
      "  Minke_Whale: 3\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 12\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 17\n",
      "  Grampus,_Rissos_Dolphin: 14\n",
      "  Harp_Seal: 10\n",
      "  Atlantic_Spotted_Dolphin: 11\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 14\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 12\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 7\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 11\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T22:29:41.165265Z",
     "start_time": "2025-07-09T22:29:41.161646Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.getcwd())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Finetuning**:"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Encoders - Scratch"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T22:40:15.124180Z",
     "start_time": "2025-07-09T22:29:41.185774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_2 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-2en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_2, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "22.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.4395280182361603\r\n",
      "         test_f1            0.38839712738990784\r\n",
      "        test_loss           1.9105955362319946\r\n",
      "     test_precision         0.4326449930667877\r\n",
      "       test_recall          0.36627334356307983\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_084014/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_084014\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Encoders - Scratch+"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T22:50:46.278480Z",
     "start_time": "2025-07-09T22:40:15.153716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_2 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-4,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-2en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_2, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "22.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.6312684416770935\r\n",
      "         test_f1            0.5585058331489563\r\n",
      "        test_loss           1.3350571393966675\r\n",
      "     test_precision         0.6224188804626465\r\n",
      "       test_recall          0.5280236005783081\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_085045/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_085045\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Encoders - Pretrained"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T23:03:06.737663Z",
     "start_time": "2025-07-09T22:50:46.307444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_2en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/2en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_2en1de, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "22.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.6755162477493286\r\n",
      "         test_f1            0.6184861063957214\r\n",
      "        test_loss           1.1979495286941528\r\n",
      "     test_precision         0.6710914373397827\r\n",
      "       test_recall          0.5929203629493713\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_090305/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_090305\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 Encoders - Scratch"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T23:22:10.822299Z",
     "start_time": "2025-07-09T23:03:06.804095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_4 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-4en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_4, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 36.0 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "36.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "36.2 M    Total params\n",
      "144.952   Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.4808259606361389\r\n",
      "         test_f1            0.42281222343444824\r\n",
      "        test_loss            1.850882649421692\r\n",
      "     test_precision         0.4719763696193695\r\n",
      "       test_recall          0.39823007583618164\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_092208/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_092208\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 Encoders - Scratch+"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T23:41:16.686167Z",
     "start_time": "2025-07-09T23:22:10.878121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_4 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-4,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-4en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_4, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 36.0 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "36.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "36.2 M    Total params\n",
      "144.952   Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.6430678367614746\r\n",
      "         test_f1            0.5899707674980164\r\n",
      "        test_loss           1.3583980798721313\r\n",
      "     test_precision         0.6381514668464661\r\n",
      "       test_recall          0.5658800601959229\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_094115/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_094115\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 Encoders - Pretrained\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T23:59:13.733179Z",
     "start_time": "2025-07-09T23:41:16.728604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_4en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/4en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_4en1de, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 36.0 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "36.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "36.2 M    Total params\n",
      "144.952   Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc             0.737463116645813\r\n",
      "         test_f1            0.6814162731170654\r\n",
      "        test_loss            0.991078794002533\r\n",
      "     test_precision         0.7335299849510193\r\n",
      "       test_recall          0.6553588509559631\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_095913/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_095913\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6 Encoders - Scratch"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T00:22:15.063937Z",
     "start_time": "2025-07-09T23:59:13.753486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_6 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"n_mels\": 128,\n",
    "     \"target_size\": 224,\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-6en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_6, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "50.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.5191740393638611\r\n",
      "         test_f1            0.4611603021621704\r\n",
      "        test_loss           1.7421637773513794\r\n",
      "     test_precision         0.5132743120193481\r\n",
      "       test_recall          0.43510323762893677\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_102214/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_102214\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6 Encoders - Scratch+"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T00:45:35.747581Z",
     "start_time": "2025-07-10T00:22:15.089389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_6 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-4,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"n_mels\": 128,\n",
    "     \"target_size\": 224,\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-6en1de-seed42.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_6, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "50.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.6135693192481995\r\n",
      "         test_f1            0.5437564253807068\r\n",
      "        test_loss           1.3545607328414917\r\n",
      "     test_precision         0.6057030558586121\r\n",
      "       test_recall          0.5127826929092407\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_104535/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_104535\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6 Encoders - Pretrained"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T01:11:15.656632Z",
     "start_time": "2025-07-10T00:45:35.777278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_6en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"n_mels\": 128,\n",
    "     \"target_size\": 224,\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/6en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_6en1de, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "50.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.7581120729446411\r\n",
      "         test_f1            0.7089482545852661\r\n",
      "        test_loss           0.9382200241088867\r\n",
      "     test_precision          0.755162239074707\r\n",
      "       test_recall          0.6858407258987427\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250710_111113/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250710_111113\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wav2Vec - Pretrained"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T01:26:08.611963Z",
     "start_time": "2025-07-10T01:11:15.676462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_wav2vec = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"facebook/wav2vec2-base\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/6en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_wav2vec, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\transformers\\configuration_utils.py:309: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | Wav2Vec2Model       | 94.4 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "94.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "94.4 M    Total params\n",
      "377.588   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "220       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.8436577916145325\r\n",
      "         test_f1            0.8072764277458191\r\n",
      "        test_loss           0.5636005997657776\r\n",
      "     test_precision          0.841691255569458\r\n",
      "       test_recall          0.7900688648223877\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250710_112607/\n",
      "Completed facebook/wav2vec2-base (FT), artifacts in notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250710_112607\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ImageNet - Pretrained"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T01:46:25.241761Z",
     "start_time": "2025-07-10T01:26:08.638028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_imagenet = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"vit-imagenet\",\n",
    "     \"n_mels\": 128,\n",
    "     \"target_size\": 224,\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/6en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_imagenet, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:30: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | ViTModel            | 85.8 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "85.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.296   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "212       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "       Test metric             DataLoader 0\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n",
      "        test_acc            0.7315634489059448\r\n",
      "         test_f1            0.6745331883430481\r\n",
      "        test_loss           1.0334111452102661\r\n",
      "     test_precision         0.7276302576065063\r\n",
      "       test_recall          0.6479842662811279\r\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Artifacts saved to notebook\\downstream\\model\\vit-imagenet_imbalance\\20250710_114624/\n",
      "Completed vit-imagenet (FT), artifacts in notebook\\downstream\\model\\vit-imagenet_imbalance\\20250710_114624\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
