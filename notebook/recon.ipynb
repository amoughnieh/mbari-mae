{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:02:34.080676Z",
     "start_time": "2025-07-17T08:02:34.065038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "os.chdir(\"../\")\n",
    "print(os.getcwd())"
   ],
   "id": "a28bb877261e20e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:35:10.299554Z",
     "start_time": "2025-07-17T08:35:06.542852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import mae_ast.tasks.mae_ast_pretraining\n",
    "import fairseq\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "\n",
    "def print_info(message):\n",
    "    print(f\"[*] {message}\")\n",
    "\n",
    "def save_with_colormap(data_tensor, filename, norm_min, norm_max, cmap='viridis'):\n",
    "\n",
    "    data_array = data_tensor.cpu().numpy().transpose()\n",
    "    if norm_max > norm_min:\n",
    "        normalized_data = (data_array - norm_min) / (norm_max - norm_min)\n",
    "    else:\n",
    "        normalized_data = np.zeros_like(data_array)\n",
    "    normalized_data = np.clip(normalized_data, 0, 1)\n",
    "    plt.imsave(filename, normalized_data[:992], cmap=cmap, vmin=0, vmax=1, origin='lower')\n",
    "    print_info(f\"Successfully saved image to {filename}\")\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    print_info(f\"Random seed set to {seed} for reproducibility.\")\n",
    "\n",
    "BASE_CONFIG_PATH = r\"config/pretrain/mae_ast - recon.yaml\"\n",
    "CHECKPOINT_DIR = r\"C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\notebook\\downstream\\load_model\"\n",
    "DATA_DIRECTORY = r\"D:\\MBARI 2KHz\\training\\input_dir\"\n",
    "OUTPUT_IMAGE_FOLDER = r\"notebook/reconstructions\"\n",
    "\n",
    "DATASET_SPLIT = 'train'\n",
    "SAMPLE_INDEX = 29664\n",
    "RANDOM_SEED = torch.randint(0, 100000, (1,))[0]\n",
    "\n",
    "MODELS_TO_TEST = [\n",
    "    {'name': '2en1de', 'file': '2en1de.pt', 'encoder_layers': 2, 'decoder_layers': 1},\n",
    "    {'name': '4en1de', 'file': '4en1de.pt', 'encoder_layers': 4, 'decoder_layers': 1},\n",
    "    {'name': '6en1de', 'file': '6en1de.pt', 'encoder_layers': 6, 'decoder_layers': 1},\n",
    "]\n",
    "\n",
    "MASKING_RATIO = 0.9\n",
    "CONTRAST_FACTOR = 15.0\n",
    "BRIGHTNESS_FACTOR = 5.0\n",
    "SAVE_IMAGES = True\n",
    "\n",
    "\n",
    "print_info(\"--- Starting Reconstruction Comparison Process ---\")\n",
    "\n",
    "base_cfg = OmegaConf.load(BASE_CONFIG_PATH)\n",
    "\n",
    "temp_cfg = base_cfg.copy()\n",
    "temp_cfg.merge_with({'task': {'data': DATA_DIRECTORY}, 'dataset': {'valid_subset': DATASET_SPLIT}})\n",
    "task = fairseq.tasks.setup_task(temp_cfg.task)\n",
    "task.load_dataset(temp_cfg.dataset.valid_subset)\n",
    "dataset = task.dataset(temp_cfg.dataset.valid_subset)\n",
    "\n",
    "sample = dataset[SAMPLE_INDEX]\n",
    "original_spectrogram_tensor = sample['source']\n",
    "\n",
    "patch_size = 16\n",
    "if original_spectrogram_tensor.shape[0] % patch_size != 0:\n",
    "    padding_needed = patch_size - (original_spectrogram_tensor.shape[0] % patch_size)\n",
    "    original_spectrogram_tensor = F.pad(original_spectrogram_tensor, (0, 0, 0, padding_needed), \"constant\", 0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_tensor = original_spectrogram_tensor.unsqueeze(0).to(device)\n",
    "padding_mask = torch.zeros(1, original_spectrogram_tensor.shape[0], dtype=torch.bool).to(device)\n",
    "\n",
    "if SAVE_IMAGES:\n",
    "    os.makedirs(OUTPUT_IMAGE_FOLDER, exist_ok=True)\n",
    "    norm_min = torch.min(original_spectrogram_tensor).item()\n",
    "    norm_max = torch.max(original_spectrogram_tensor).item()\n",
    "    save_with_colormap(\n",
    "        original_spectrogram_tensor[:992],\n",
    "        os.path.join(OUTPUT_IMAGE_FOLDER, f\"{SAMPLE_INDEX}-original.png\"),\n",
    "        norm_min, norm_max\n",
    "    )\n",
    "\n",
    "print_info(\"\\n--- Starting Model Comparison Loop ---\")\n",
    "is_first_run = True # Flag to save the masked image only once\n",
    "\n",
    "for model_info in MODELS_TO_TEST:\n",
    "    model_name = model_info['name']\n",
    "    print_info(f\"\\n--- Processing model: {model_name} ---\")\n",
    "\n",
    "    set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    cfg = base_cfg.copy()\n",
    "    cfg.merge_with({\n",
    "        'task': {'data': DATA_DIRECTORY},\n",
    "        'model': {\n",
    "            'random_mask_prob': MASKING_RATIO,\n",
    "            'encoder_layers': model_info['encoder_layers'],\n",
    "            'decoder_layers': model_info['decoder_layers'],\n",
    "        }\n",
    "    })\n",
    "    model = task.build_model(cfg.model)\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, model_info['file'])\n",
    "    print_info(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print_info(\"Running model forward pass to generate mask and reconstruct...\")\n",
    "    with torch.no_grad():\n",
    "        model_output = model.forward(\n",
    "            source=batch_tensor,\n",
    "            padding_mask=padding_mask,\n",
    "            mask=True\n",
    "        )\n",
    "\n",
    "    mask_indices = model_output['mask_indices'].squeeze(0)\n",
    "    all_patches = model.unfold(batch_tensor.unsqueeze(1)).squeeze(0).transpose(0, 1)\n",
    "\n",
    "    if is_first_run and SAVE_IMAGES:\n",
    "        print_info(\"Saving masked image (only once)...\")\n",
    "        p_c = cfg.model.ast_kernel_size_chan\n",
    "        p_t = cfg.model.ast_kernel_size_time\n",
    "        h, w = original_spectrogram_tensor.shape\n",
    "        folder = torch.nn.Fold(output_size=(h, w), kernel_size=(p_c, p_t), stride=(p_c, p_t))\n",
    "\n",
    "        masked_patches = all_patches.clone()\n",
    "        masked_patches[mask_indices] = torch.min(all_patches)\n",
    "        masked_data = masked_patches.transpose(0, 1).unsqueeze(0)\n",
    "        masked_tensor = folder(masked_data).squeeze()\n",
    "        save_with_colormap(\n",
    "            masked_tensor[:992],\n",
    "            os.path.join(OUTPUT_IMAGE_FOLDER, f\"{SAMPLE_INDEX}-{MASKING_RATIO}-{model_name}-masked.png\"),\n",
    "            norm_min, norm_max\n",
    "        )\n",
    "        is_first_run = False\n",
    "\n",
    "    reconstructed_patches = model_output['logit_m_list_recon'].squeeze(0)\n",
    "    mean_p = torch.mean(reconstructed_patches)\n",
    "    adjusted_recons_patches = mean_p + CONTRAST_FACTOR * (reconstructed_patches - mean_p)\n",
    "    adjusted_recons_patches = adjusted_recons_patches - BRIGHTNESS_FACTOR\n",
    "    recon_patches = all_patches.clone()\n",
    "    recon_patches[mask_indices] = adjusted_recons_patches\n",
    "    recon_data = recon_patches.transpose(0, 1).unsqueeze(0)\n",
    "    if 'folder' not in locals():\n",
    "        p_c = cfg.model.ast_kernel_size_chan\n",
    "        p_t = cfg.model.ast_kernel_size_time\n",
    "        h, w = original_spectrogram_tensor.shape\n",
    "        folder = torch.nn.Fold(output_size=(h, w), kernel_size=(p_c, p_t), stride=(p_c, p_t))\n",
    "    reconstructed_tensor = folder(recon_data).squeeze()\n",
    "\n",
    "    if SAVE_IMAGES:\n",
    "        output_filename = os.path.join(OUTPUT_IMAGE_FOLDER, f\"{SAMPLE_INDEX}-{MASKING_RATIO}-{model_name}-recon.png\")\n",
    "        save_with_colormap(reconstructed_tensor[:992], output_filename, norm_min, norm_max)\n",
    "\n",
    "print_info(\"\\n--- All models processed. Comparison complete. ---\")"
   ],
   "id": "1f391af855db3244",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] --- Starting Reconstruction Comparison Process ---\n",
      "[*] Successfully saved image to notebook/reconstructions\\29664-original.png\n",
      "[*] \n",
      "--- Starting Model Comparison Loop ---\n",
      "[*] \n",
      "--- Processing model: 2en1de ---\n",
      "[*] Random seed set to 80298 for reproducibility.\n",
      "[*] Loading checkpoint: C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\notebook\\downstream\\load_model\\2en1de.pt\n",
      "[*] Running model forward pass to generate mask and reconstruct...\n",
      "[*] Saving masked image (only once)...\n",
      "[*] Successfully saved image to notebook/reconstructions\\29664-0.9-2en1de-masked.png\n",
      "[*] Successfully saved image to notebook/reconstructions\\29664-0.9-2en1de-recon.png\n",
      "[*] \n",
      "--- Processing model: 4en1de ---\n",
      "[*] Random seed set to 80298 for reproducibility.\n",
      "[*] Loading checkpoint: C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\notebook\\downstream\\load_model\\4en1de.pt\n",
      "[*] Running model forward pass to generate mask and reconstruct...\n",
      "[*] Successfully saved image to notebook/reconstructions\\29664-0.9-4en1de-recon.png\n",
      "[*] \n",
      "--- Processing model: 6en1de ---\n",
      "[*] Random seed set to 80298 for reproducibility.\n",
      "[*] Loading checkpoint: C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\notebook\\downstream\\load_model\\6en1de.pt\n",
      "[*] Running model forward pass to generate mask and reconstruct...\n",
      "[*] Successfully saved image to notebook/reconstructions\\29664-0.9-6en1de-recon.png\n",
      "[*] \n",
      "--- All models processed. Comparison complete. ---\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "485be83ef3ec116c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
