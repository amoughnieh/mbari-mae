{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:19:48.879356Z",
     "start_time": "2025-07-06T07:19:48.874499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zqEAfZZYIaiX"
   },
   "source": [
    "# Standard library\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "\n",
    "# Numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2Model,\n",
    ")\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "\n",
    "# Metrics\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MAE-AST Library\n",
    "from s3prl.nn.upstream import S3PRLUpstream\n",
    "\n",
    "# Fix the length of the input audio to the same length\n",
    "def _match_length_force(self, xs, target_max_len):\n",
    "    xs_max_len = xs.size(1)\n",
    "    if xs_max_len > target_max_len:\n",
    "        xs = xs[:, :target_max_len, :]\n",
    "    elif xs_max_len < target_max_len:\n",
    "        pad_len = target_max_len - xs_max_len\n",
    "        xs = torch.cat(\n",
    "            (xs, xs[:, -1:, :].repeat(1, pad_len, 1)),\n",
    "            dim=1\n",
    "        )\n",
    "    return xs\n",
    "\n",
    "S3PRLUpstream._match_length = _match_length_force"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:20:04.056408Z",
     "start_time": "2025-07-06T07:20:04.044227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark     = False\n",
    "    pl.seed_everything(seed, workers=True)\n",
    "\n",
    "set_seed(42)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C5aQ8ZsGkD7s",
    "ExecuteTime": {
     "end_time": "2025-07-06T07:20:06.791041Z",
     "start_time": "2025-07-06T07:20:05.862652Z"
    }
   },
   "source": [
    "set_seed(42)\n",
    "# loading the dataset\n",
    "data_dir = os.path.join(\"data\", \"watkins\")\n",
    "annotations_file_train = os.path.join(data_dir, \"annotations.train.csv\")\n",
    "annotations_file_valid = os.path.join(data_dir, \"annotations.valid.csv\")\n",
    "annotations_file_test = os.path.join(data_dir, \"annotations.test.csv\")\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\"train\": annotations_file_train,\n",
    "                \"validation\": annotations_file_valid,\n",
    "                \"test\": annotations_file_test},\n",
    ")\n",
    "\n",
    "for split_name in [\"train\", \"validation\", \"test\"]:\n",
    "    split_dataset = ds[split_name]\n",
    "    labels = split_dataset[\"label\"]\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "\n",
    "    print(f\"{split_name.capitalize()} dataset: {total} examples, {len(counts)} classes\")\n",
    "    if \"label\" in split_dataset.features and hasattr(split_dataset.features[\"label\"], \"names\"):\n",
    "        class_names = split_dataset.features[\"label\"].names\n",
    "        for idx, name in enumerate(class_names):\n",
    "            print(f\"  {idx} ({name}): {counts.get(name, 0)}\")\n",
    "    else:\n",
    "        for label, count in counts.items():\n",
    "            print(f\"  {label}: {count}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1017 examples, 31 classes\n",
      "  Clymene_Dolphin: 38\n",
      "  Bottlenose_Dolphin: 15\n",
      "  Spinner_Dolphin: 69\n",
      "  Beluga,_White_Whale: 30\n",
      "  Bearded_Seal: 22\n",
      "  Minke_Whale: 10\n",
      "  Humpback_Whale: 38\n",
      "  Southern_Right_Whale: 15\n",
      "  White-sided_Dolphin: 33\n",
      "  Narwhal: 30\n",
      "  White-beaked_Dolphin: 34\n",
      "  Northern_Right_Whale: 32\n",
      "  Frasers_Dolphin: 52\n",
      "  Grampus,_Rissos_Dolphin: 40\n",
      "  Harp_Seal: 28\n",
      "  Atlantic_Spotted_Dolphin: 35\n",
      "  Fin,_Finback_Whale: 30\n",
      "  Ross_Seal: 30\n",
      "  Rough-Toothed_Dolphin: 30\n",
      "  Killer_Whale: 21\n",
      "  Pantropical_Spotted_Dolphin: 40\n",
      "  Short-Finned_Pacific_Pilot_Whale: 40\n",
      "  Bowhead_Whale: 36\n",
      "  False_Killer_Whale: 35\n",
      "  Melon_Headed_Whale: 38\n",
      "  Long-Finned_Pilot_Whale: 42\n",
      "  Striped_Dolphin: 49\n",
      "  Leopard_Seal: 6\n",
      "  Walrus: 23\n",
      "  Sperm_Whale: 45\n",
      "  Common_Dolphin: 31\n",
      "Validation dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 12\n",
      "  Bottlenose_Dolphin: 5\n",
      "  Spinner_Dolphin: 23\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 7\n",
      "  Minke_Whale: 4\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 11\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 18\n",
      "  Grampus,_Rissos_Dolphin: 13\n",
      "  Harp_Seal: 9\n",
      "  Atlantic_Spotted_Dolphin: 12\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 13\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 13\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 8\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 10\n",
      "Test dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 13\n",
      "  Bottlenose_Dolphin: 4\n",
      "  Spinner_Dolphin: 22\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 8\n",
      "  Minke_Whale: 3\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 12\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 17\n",
      "  Grampus,_Rissos_Dolphin: 14\n",
      "  Harp_Seal: 10\n",
      "  Atlantic_Spotted_Dolphin: 11\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 14\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 12\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 7\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 11\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:20:09.148484Z",
     "start_time": "2025-07-06T07:20:09.132630Z"
    }
   },
   "source": [
    "set_seed(42)\n",
    "# class weights calculation\n",
    "train_labels = ds[\"train\"][\"label\"]\n",
    "unique_labels = sorted(set(train_labels))\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_train = [label_to_int[lbl] for lbl in train_labels]\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(unique_labels)),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "num_classes = len(class_weights)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6JYR66KeIUsg",
    "ExecuteTime": {
     "end_time": "2025-07-06T07:20:10.337482Z",
     "start_time": "2025-07-06T07:20:10.309847Z"
    }
   },
   "source": [
    "# model definition\n",
    "class WMMDClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        backbone_lr: float = 1e-5,\n",
    "        head_lr: float = 1e-4,\n",
    "        weight_decay: float = 0.05,\n",
    "        max_epochs = 100,\n",
    "        backbone: str = \"facebook/wav2vec2-base\",\n",
    "        ckpt_path: str = \"\",\n",
    "        finetune: bool = False,\n",
    "        class_weights=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        if backbone == \"facebook/wav2vec2-base\":\n",
    "            self.backbone     = Wav2Vec2Model.from_pretrained(backbone)\n",
    "            self.embedding_dim = self.backbone.config.hidden_size\n",
    "        \n",
    "        elif backbone == \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\":\n",
    "            self.backbone     = Wav2Vec2Model.from_pretrained(backbone)\n",
    "            self.embedding_dim = self.backbone.config.hidden_size\n",
    "        \n",
    "        elif backbone.lower() == \"mae-ast\":\n",
    "            #up_kwargs = {\"name\": \"mae_ast_patch\"}\n",
    "            #s3 = S3PRLUpstream(**up_kwargs)\n",
    "\n",
    "            # Check for the local checkpoint path first.\n",
    "            if not ckpt_path:\n",
    "                raise ValueError(\"For 'mae-ast' backbone, a local ckpt_path must be provided.\")\n",
    "\n",
    "            from s3prl.upstream.mae_ast.expert import UpstreamExpert\n",
    "            self.backbone = UpstreamExpert(ckpt=ckpt_path)\n",
    "            self.embedding_dim = 6144\n",
    "\n",
    "            enc = self.backbone.model.encoder #s3.upstream.model.encoder\n",
    "            enc.layers = nn.ModuleList(list(enc.layers))\n",
    "            self.backbone.dec_sine_pos_embed = None\n",
    "            self.backbone.decoder = None\n",
    "            self.backbone.final_proj_reconstruction = None\n",
    "            self.backbone.final_proj_classification  = None\n",
    "\n",
    "\n",
    "            mel_transform = T.MelSpectrogram(\n",
    "                sample_rate=2000, n_fft=1024, win_length=512,\n",
    "                hop_length=20, n_mels=128,\n",
    "            )\n",
    "\n",
    "            class DBWithDeltas(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, spec):\n",
    "                    spec_db = F.amplitude_to_DB(\n",
    "                        spec,\n",
    "                        multiplier=10.0,\n",
    "                        amin=1e-10,\n",
    "                        db_multiplier=0\n",
    "                    )\n",
    "                    t = spec_db.transpose(0, 1)\n",
    "                    d1 = F.compute_deltas(t.transpose(0,1))\n",
    "                    d2 = F.compute_deltas(d1)\n",
    "                    return torch.cat([\n",
    "                        t,\n",
    "                        d1.transpose(0,1),\n",
    "                        d2.transpose(0,1)\n",
    "                    ], dim=1)\n",
    "            \n",
    "            self.backbone.model.fbank   = mel_transform\n",
    "            self.backbone.model.db_norm = DBWithDeltas()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone '{backbone}'\")\n",
    "\n",
    "        try:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = finetune\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.embedding_dim, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "        if class_weights is not None:\n",
    "            cw = torch.tensor(class_weights, dtype=torch.float)\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=cw)\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        metrics_kwargs = dict(num_classes=num_classes, average='macro')\n",
    "        self.train_precision = MulticlassPrecision(**metrics_kwargs)\n",
    "        self.train_recall = MulticlassRecall(**metrics_kwargs)\n",
    "        self.train_f1 = MulticlassF1Score(**metrics_kwargs)\n",
    "        self.val_precision = MulticlassPrecision(**metrics_kwargs)\n",
    "        self.val_recall = MulticlassRecall(**metrics_kwargs)\n",
    "        self.val_f1 = MulticlassF1Score(**metrics_kwargs)\n",
    "        self.test_precision = MulticlassPrecision(**metrics_kwargs)\n",
    "        self.test_recall = MulticlassRecall(**metrics_kwargs)\n",
    "        self.test_f1 = MulticlassF1Score(**metrics_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bname = self.hparams.backbone.lower()\n",
    "        if bname == \"facebook/wav2vec2-base\":\n",
    "            out = self.backbone(x)\n",
    "            hidden = out.last_hidden_state\n",
    "        elif bname == \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\":\n",
    "            out = self.backbone(x)\n",
    "            hidden = out.last_hidden_state\n",
    "        elif bname == \"mae-ast\":\n",
    "            if x.dim() == 3:\n",
    "                x = x.squeeze(-1)\n",
    "\n",
    "            output_dict = self.backbone(x)\n",
    "            hidden = output_dict[\"hidden_states\"][-1]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone in forward(): '{self.hparams.backbone}'\")\n",
    "\n",
    "        emb = hidden.mean(dim=1)\n",
    "\n",
    "        return self.classifier(emb)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        self.log_batch_metrics(loss, preds, y, prefix='train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        self.log_batch_metrics(loss, preds, y, prefix='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        self.log_batch_metrics(loss, preds, y, prefix='test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        backbone_params = list(self.backbone.parameters())\n",
    "        head_params     = list(self.classifier.parameters())\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            [\n",
    "                {\"params\": backbone_params, \"lr\": self.hparams.backbone_lr},\n",
    "                {\"params\": head_params,     \"lr\": self.hparams.head_lr},\n",
    "            ],\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "\n",
    "        total_steps = self.trainer.estimated_stepping_batches\n",
    "\n",
    "        warmup_steps = int(0.05 * total_steps)\n",
    "\n",
    "        def lr_lambda(current_step: int):\n",
    "            if current_step < warmup_steps:\n",
    "                # linear warm‑up\n",
    "                return float(current_step) / float(max(1, warmup_steps))\n",
    "            # cosine decay after warm‑up\n",
    "            progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "            return 0.5 * (1.0 + np.cos(np.pi * progress))\n",
    "\n",
    "        scheduler = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda),\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "\n",
    "    def log_batch_metrics(self, loss, preds, targets, prefix):\n",
    "        self.log(f'{prefix}_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        acc = (preds == targets).float().mean()\n",
    "        self.log(f'{prefix}_acc', acc, prog_bar=True, on_epoch=True)\n",
    "        precision = getattr(self, f'{prefix}_precision')(preds, targets)\n",
    "        recall = getattr(self, f'{prefix}_recall')(preds, targets)\n",
    "        f1 = getattr(self, f'{prefix}_f1')(preds, targets)\n",
    "        self.log(f'{prefix}_precision', precision, on_epoch=True)\n",
    "        self.log(f'{prefix}_recall', recall, on_epoch=True)\n",
    "        self.log(f'{prefix}_f1', f1, on_epoch=True)\n",
    "\n",
    "    def on_train_end(self):\n",
    "        save_dir = getattr(self, 'save_dir', None)\n",
    "        if save_dir:\n",
    "            self.save_model(save_dir)\n",
    "\n",
    "    def save_model(self):\n",
    "        base_dir = os.path.join('notebook', 'downstream')\n",
    "        base_dir = os.path.join(base_dir, 'model')\n",
    "        bn = self.hparams.backbone.replace('/', '_')\n",
    "        cw = getattr(self.hparams, 'class_weights', None)\n",
    "        balance_flag = 'imbalance' if cw is not None else 'balance'\n",
    "        timestamp = getattr(self, 'finish_time', datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "        folder = os.path.join(base_dir, f\"{bn}_{balance_flag}\", timestamp)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        ckpt_path = os.path.join(folder, f\"{timestamp}.pt\")\n",
    "        payload = {\n",
    "            'state_dict': self.state_dict(),\n",
    "            'hparams': dict(self.hparams)\n",
    "        }\n",
    "        for attr in ('test_results', 'finish_time', 'epochs_trained'):\n",
    "            if hasattr(self, attr):\n",
    "                payload[attr] = getattr(self, attr)\n",
    "        torch.save(payload, ckpt_path)\n",
    "\n",
    "        stats_path = os.path.join(folder, f\"{timestamp}.txt\")\n",
    "        raw_hparams = dict(self.hparams)\n",
    "        serializable_hparams = {}\n",
    "        for k, v in raw_hparams.items():\n",
    "            if isinstance(v, np.ndarray):\n",
    "                serializable_hparams[k] = v.tolist()\n",
    "            elif isinstance(v, torch.Tensor):\n",
    "                serializable_hparams[k] = v.cpu().item() if v.ndim == 0 else v.cpu().tolist()\n",
    "            else:\n",
    "                serializable_hparams[k] = v\n",
    "\n",
    "        serializable_results = {}\n",
    "        if hasattr(self, 'test_results'):\n",
    "            for k, v in self.test_results.items():\n",
    "                serializable_results[k] = v.cpu().item() if isinstance(v, torch.Tensor) else v\n",
    "\n",
    "        with open(stats_path, 'w') as f:\n",
    "            f.write(f\"Model architecture:\\n{self}\\n\\n\")\n",
    "            f.write(\"Hyperparameters:\\n\")\n",
    "            f.write(json.dumps(serializable_hparams, indent=4))\n",
    "            f.write(\"\\n\\n\")\n",
    "            if serializable_results:\n",
    "                f.write(\"Test results:\\n\")\n",
    "                f.write(json.dumps(serializable_results, indent=4))\n",
    "                f.write(\"\\n\\n\")\n",
    "            if hasattr(self, 'epochs_trained'):\n",
    "                f.write(f\"Epochs trained: {self.epochs_trained}\\n\")\n",
    "\n",
    "        self._last_save_dir = folder\n",
    "        self._last_timestamp = timestamp\n",
    "        print(f\"Artifacts saved to {folder}/\")\n",
    "    \n",
    "    def load_mae_ckpt(self, ckpt_source: str):\n",
    "\n",
    "        loaded = torch.load(ckpt_source)\n",
    "        state_dict = loaded.get('model', loaded)\n",
    "\n",
    "        up = self.backbone.upstream.model\n",
    "        up_state = up.state_dict()\n",
    "\n",
    "        to_load = {k: v for k, v in state_dict.items()\n",
    "                   if k in up_state and v.shape == up_state[k].shape}\n",
    "\n",
    "        missing, unexpected = up.load_state_dict(to_load, strict=False)\n",
    "\n",
    "        for k, v in to_load.items():\n",
    "            if not torch.equal(up_state[k], v):\n",
    "                raise RuntimeError(f\"Weight mismatch at '{k}' after loading checkpoint\")\n",
    "\n",
    "        print(f\"Successfully loaded {len(to_load)} parameters; missing: {len(missing)}, unexpected: {len(unexpected)}\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, load_dir: str, map_location=None):\n",
    "\n",
    "        hparams_path = os.path.join(load_dir, 'hparams.json')\n",
    "        with open(hparams_path, 'r') as f:\n",
    "            hparams = json.load(f)\n",
    "\n",
    "        model = cls(**hparams)\n",
    "        ckpt_path = os.path.join(load_dir, f'{cls.__name__}.ckpt')\n",
    "        state = torch.load(ckpt_path, map_location=map_location)\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        return model"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:20:12.407186Z",
     "start_time": "2025-07-06T07:20:11.501080Z"
    }
   },
   "source": [
    "set_seed(42)\n",
    "# sanity check\n",
    "model = WMMDClassifier(\n",
    "        num_classes=31,\n",
    "        backbone=\"patrickvonplaten/tiny-wav2vec2-no-tokenizer\", finetune=True,\n",
    "        class_weights=class_weights,\n",
    "        ckpt_path=\"\"\n",
    "    )\n",
    "\n",
    "print(ModelSummary(model, max_depth=1))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | Wav2Vec2Model       | 26.7 K | eval \n",
      "1  | classifier      | Sequential          | 49.2 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "75.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "75.9 K    Total params\n",
      "0.304     Total estimated model params size (MB)\n",
      "16        Modules in train mode\n",
      "88        Modules in eval mode\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:20:34.842502Z",
     "start_time": "2025-07-06T07:20:33.904859Z"
    }
   },
   "source": [
    "set_seed(42)\n",
    "# sanity check\n",
    "model = WMMDClassifier(\n",
    "    num_classes=31,\n",
    "    backbone_lr= 1e-5,\n",
    "    head_lr= 1e-4,\n",
    "    backbone=\"mae-ast\",\n",
    "    finetune=True,\n",
    "    class_weights=class_weights,\n",
    "    ckpt_path=\"notebook/downstream/load_model/random-4en1de.pt\"\n",
    "    )\n",
    "\n",
    "print(ModelSummary(model, max_depth=1))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 36.0 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "42.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "42.4 M    Total params\n",
      "169.438   Total estimated model params size (MB)\n",
      "108       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ycDcNmcwQ_ON",
    "ExecuteTime": {
     "end_time": "2025-07-06T07:20:37.062852Z",
     "start_time": "2025-07-06T07:20:37.050292Z"
    }
   },
   "source": [
    "def WMMD_Collate(batch):\n",
    "    waveforms, labels = zip(*batch)\n",
    "\n",
    "    lengths    = [w.shape[0] for w in waveforms]\n",
    "    raw_max    = max(lengths)\n",
    "\n",
    "    min_len    = 5_000\n",
    "    max_len    = 25_000\n",
    "    target_len = min(max(raw_max, min_len), max_len)\n",
    "\n",
    "    padded_waveforms = []\n",
    "    for w in waveforms:\n",
    "        L = w.shape[0]\n",
    "\n",
    "        if L > target_len:\n",
    "            start = random.randint(0, L - target_len)\n",
    "            w2    = w[start : start + target_len]\n",
    "\n",
    "        elif L < target_len:\n",
    "            pad_amt = target_len - L\n",
    "            w2      = torch.nn.functional.pad(w, (0, pad_amt))\n",
    "\n",
    "        else:\n",
    "            w2 = w\n",
    "\n",
    "        padded_waveforms.append(w2)\n",
    "\n",
    "    batch_waveforms = torch.stack(padded_waveforms, dim=0)\n",
    "    batch_labels    = torch.tensor(labels, dtype=torch.long)\n",
    "    return batch_waveforms, batch_labels\n",
    "\n",
    "class WMMDSoundDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, backbone: str, target_sr: int = 2000):\n",
    "        \"\"\"\n",
    "        dataset: list of dicts with keys 'path' & 'label'\n",
    "        backbone: 'facebook/wav2vec2-base' or 'mae-ast'\n",
    "        target_sr: sampling rate (e.g. 2000)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.backbone = backbone.lower()\n",
    "        self.target_sr = target_sr\n",
    "        self.resampler_cache = {}\n",
    "\n",
    "        if self.backbone == \"facebook/wav2vec2-base\":\n",
    "            self.processor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "                \"facebook/wav2vec2-base\", return_attention_mask=False, sampling_rate=target_sr\n",
    "            )\n",
    "        elif self.backbone == \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\":\n",
    "            self.processor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "                \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\", return_attention_mask=False, sampling_rate=target_sr\n",
    "            )\n",
    "        elif self.backbone == \"mae-ast\":\n",
    "            self.processor = None\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone '{backbone}'\")\n",
    "\n",
    "        labels = sorted({item['label'] for item in dataset})\n",
    "        self.label_to_int = {lbl: i for i, lbl in enumerate(labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        audio_path = item[\"path\"]\n",
    "        waveform, orig_sr = torchaudio.load(audio_path)\n",
    "\n",
    "        if orig_sr != self.target_sr:\n",
    "            if orig_sr not in self.resampler_cache:\n",
    "                self.resampler_cache[orig_sr] = torchaudio.transforms.Resample(orig_sr, self.target_sr)\n",
    "            waveform = self.resampler_cache[orig_sr](waveform)\n",
    "\n",
    "        waveform = waveform / (waveform.abs().max() + 1e-6)\n",
    "        wav_1d = waveform.squeeze(0)  \n",
    "        \n",
    "        if self.backbone == \"facebook/wav2vec2-base\":\n",
    "            arr = wav_1d.numpy()\n",
    "            feats = self.processor(arr, sampling_rate=self.target_sr, return_tensors=\"pt\")\n",
    "            inp = feats.input_values.squeeze(0)\n",
    "        elif self.backbone == \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\":\n",
    "            arr = wav_1d.numpy()\n",
    "            feats = self.processor(arr, sampling_rate=self.target_sr, return_tensors=\"pt\")\n",
    "            inp = feats.input_values.squeeze(0)\n",
    "        elif self.backbone == \"mae-ast\":\n",
    "            inp = wav_1d\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone '{self.backbone}'\")\n",
    "\n",
    "        lbl = self.label_to_int[item['label']]\n",
    "        return inp, lbl\n",
    "\n",
    "class WMMDDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_dict,\n",
    "        backbone: str,\n",
    "        batch_size: int = 2,\n",
    "        num_workers: int = 1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dataset_dict = dataset_dict\n",
    "        self.backbone = backbone\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_ds = WMMDSoundDataset(self.dataset_dict[\"train\"], backbone=self.backbone)\n",
    "        self.val_ds   = WMMDSoundDataset(self.dataset_dict[\"validation\"], backbone=self.backbone)\n",
    "        self.test_ds  = WMMDSoundDataset(self.dataset_dict[\"test\"], backbone=self.backbone)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=WMMD_Collate\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=WMMD_Collate\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=WMMD_Collate\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kQ2XWE-pRKAM",
    "ExecuteTime": {
     "end_time": "2025-07-06T07:20:38.807842Z",
     "start_time": "2025-07-06T07:20:38.801883Z"
    }
   },
   "source": [
    "# callback for logging metrics\n",
    "class MetricsLogger(pl.Callback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "        self.train_precisions = []\n",
    "        self.val_precisions = []\n",
    "        self.train_recalls = []\n",
    "        self.val_recalls = []\n",
    "        self.train_f1s = []\n",
    "        self.val_f1s = []\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        m = trainer.callback_metrics\n",
    "        self.train_losses.append(m['train_loss'].item())\n",
    "        self.train_accs.append(m['train_acc'].item())\n",
    "        self.train_precisions.append(m['train_precision'].item())\n",
    "        self.train_recalls.append(m['train_recall'].item())\n",
    "        self.train_f1s.append(m['train_f1'].item())\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        m = trainer.callback_metrics\n",
    "        self.val_losses.append(m['val_loss'].item())\n",
    "        self.val_accs.append(m['val_acc'].item())\n",
    "        self.val_precisions.append(m['val_precision'].item())\n",
    "        self.val_recalls.append(m['val_recall'].item())\n",
    "        self.val_f1s.append(m['val_f1'].item())\n",
    "\n",
    "# callback for early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    min_delta=0.01,\n",
    "    verbose=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "id": "9k7VBnf5TWfW",
    "ExecuteTime": {
     "end_time": "2025-07-06T07:22:31.068801Z",
     "start_time": "2025-07-06T07:22:31.063404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_finetune(cfg, early_stopping=False):\n",
    "    # training Loops\n",
    "    for cfg in cfg:\n",
    "        dm = WMMDDataModule(\n",
    "            dataset_dict=ds,\n",
    "            backbone=cfg[\"backbone\"],\n",
    "            batch_size=2,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        model = WMMDClassifier(\n",
    "            num_classes=cfg['num_classes'],\n",
    "            backbone_lr=cfg['backbone_lr'],\n",
    "            head_lr=cfg['head_lr'],\n",
    "            weight_decay=cfg['weight_decay'],\n",
    "            backbone=cfg['backbone'], finetune=cfg['finetune'],\n",
    "            class_weights=cfg['class_weights'],\n",
    "            ckpt_path=cfg['ckpt_path'],\n",
    "            max_epochs=cfg['max_epochs']\n",
    "        )\n",
    "        metrics_cb = MetricsLogger()\n",
    "\n",
    "        if early_stopping:\n",
    "            callbacks = [metrics_cb, early_stopping]\n",
    "        else:\n",
    "            callbacks = [metrics_cb]\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=cfg['max_epochs'],\n",
    "            accelerator='gpu', devices=1,\n",
    "            precision='16-mixed', accumulate_grad_batches=2,\n",
    "            check_val_every_n_epoch=1,\n",
    "            num_sanity_val_steps=0,\n",
    "            enable_progress_bar=False, log_every_n_steps=50,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        trainer.fit(model, dm)\n",
    "        test_res = trainer.test(model, dm)[0]\n",
    "\n",
    "        model.test_results = test_res\n",
    "        model.finish_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model.epochs_trained = trainer.current_epoch + 1\n",
    "        model.save_model()\n",
    "\n",
    "        metrics_map = {\n",
    "            'accuracy':   ('train_accs',      'val_accs'),\n",
    "            'precision':  ('train_precisions','val_precisions'),\n",
    "            'recall':     ('train_recalls',   'val_recalls'),\n",
    "            'f1_score':   ('train_f1s',       'val_f1s'),\n",
    "        }\n",
    "\n",
    "        for metric_name, (train_attr, val_attr) in metrics_map.items():\n",
    "            train_vals = getattr(metrics_cb, train_attr)\n",
    "            val_vals = getattr(metrics_cb, val_attr)\n",
    "            epochs = list(range(1, len(train_vals) + 1))\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs, train_vals, label=f'train_{metric_name}')\n",
    "            plt.plot(epochs, val_vals,   label=f'val_{metric_name}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(metric_name.replace('_', ' ').title())\n",
    "            plt.title(f\"{metric_name.replace('_', ' ').title()} over Epochs {model._last_timestamp}\")\n",
    "            plt.grid(True)\n",
    "            plt.legend(loc='best')\n",
    "\n",
    "            plot_file = os.path.join(model._last_save_dir, f\"{model._last_timestamp}_{metric_name}.png\")\n",
    "            plt.savefig(plot_file)\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"Completed {cfg['backbone']} ({'FT' if cfg['finetune'] else 'Frozen'}), artifacts in {model._last_save_dir}\")\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T22:23:16.416642Z",
     "start_time": "2025-07-05T22:23:16.414156Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 49,
   "source": [
    "# model configurations\n",
    "model_configs = [\n",
    "    # {\"num_classes\": num_classes, \"lr\": 1e-3, \"backbone\": \"facebook/wav2vec2-base\",  \"finetune\": False, \"class_weights\": class_weights, \"max_epochs\": 500, \"ckpt_path\": \"\"},\n",
    "    {\"num_classes\": num_classes, \"lr\": 1e-6, \"backbone\": \"mae-ast\",  \"finetune\": True, \"class_weights\": class_weights, \"max_epochs\": 400, \"ckpt_path\": \"random-4en1de.pt\"},\n",
    "    # {\"num_classes\": num_classes, \"lr\": 1e-3, \"backbone\": \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\",  \"finetune\": True, \"class_weights\": class_weights, \"max_epochs\": 500, \"ckpt_path\": \"\"},\n",
    "]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2 Encoders - Random weights (scratch)\n",
    "\n",
    "Starting with same arch. as our pretrained 2 encoder model, just with random weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T09:03:45.931497Z",
     "start_time": "2025-07-06T08:57:30.831531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_2 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-2en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_2, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.735   Total estimated model params size (MB)\n",
      "80        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.6076695919036865\r\n",
      "         test_f1            0.5427730083465576\r\n",
      "        test_loss           1.4022549390792847\r\n",
      "     test_precision         0.5993116497993469\r\n",
      "       test_recall          0.5152408480644226\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250706_190345/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250706_190345\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Encoders - Pretrained"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:41:33.031850Z",
     "start_time": "2025-07-06T07:31:32.173707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_2en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/2en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_2en1de, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.735   Total estimated model params size (MB)\n",
      "80        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.6312684416770935\r\n",
      "         test_f1            0.5604722499847412\r\n",
      "        test_loss           1.3492323160171509\r\n",
      "     test_precision         0.6229105591773987\r\n",
      "       test_recall          0.5299901962280273\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250706_174132/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250706_174132\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4 Encoders - Random weights (scratch)\n",
    "\n",
    "Starting with same arch. as our pretrained 4 encoder model, just with random weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T08:39:54.220039Z",
     "start_time": "2025-07-06T08:37:40.524711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_4 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-4en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_4, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 36.0 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "42.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "42.4 M    Total params\n",
      "169.438   Total estimated model params size (MB)\n",
      "108       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     47\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(*args, **kwargs)\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:599\u001B[39m, in \u001B[36mTrainer._fit_impl\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    593\u001B[39m ckpt_path = \u001B[38;5;28mself\u001B[39m._checkpoint_connector._select_ckpt_path(\n\u001B[32m    594\u001B[39m     \u001B[38;5;28mself\u001B[39m.state.fn,\n\u001B[32m    595\u001B[39m     ckpt_path,\n\u001B[32m    596\u001B[39m     model_provided=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    597\u001B[39m     model_connected=\u001B[38;5;28mself\u001B[39m.lightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    598\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m599\u001B[39m \u001B[38;5;28mself\u001B[39m._run(model, ckpt_path=ckpt_path)\n\u001B[32m    601\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.state.stopped\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1012\u001B[39m, in \u001B[36mTrainer._run\u001B[39m\u001B[34m(self, model, ckpt_path)\u001B[39m\n\u001B[32m   1009\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m   1010\u001B[39m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[32m   1011\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1012\u001B[39m results = \u001B[38;5;28mself\u001B[39m._run_stage()\n\u001B[32m   1014\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m   1015\u001B[39m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[32m   1016\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1056\u001B[39m, in \u001B[36mTrainer._run_stage\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1055\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.autograd.set_detect_anomaly(\u001B[38;5;28mself\u001B[39m._detect_anomaly):\n\u001B[32m-> \u001B[39m\u001B[32m1056\u001B[39m     \u001B[38;5;28mself\u001B[39m.fit_loop.run()\n\u001B[32m   1057\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:216\u001B[39m, in \u001B[36m_FitLoop.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28mself\u001B[39m.on_advance_start()\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m \u001B[38;5;28mself\u001B[39m.advance()\n\u001B[32m    217\u001B[39m \u001B[38;5;28mself\u001B[39m.on_advance_end()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:455\u001B[39m, in \u001B[36m_FitLoop.advance\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    454\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m._data_fetcher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m455\u001B[39m \u001B[38;5;28mself\u001B[39m.epoch_loop.run(\u001B[38;5;28mself\u001B[39m._data_fetcher)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:152\u001B[39m, in \u001B[36m_TrainingEpochLoop.run\u001B[39m\u001B[34m(self, data_fetcher)\u001B[39m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m152\u001B[39m     \u001B[38;5;28mself\u001B[39m.advance(data_fetcher)\n\u001B[32m    153\u001B[39m     \u001B[38;5;28mself\u001B[39m.on_advance_end(data_fetcher)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:344\u001B[39m, in \u001B[36m_TrainingEpochLoop.advance\u001B[39m\u001B[34m(self, data_fetcher)\u001B[39m\n\u001B[32m    342\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m trainer.lightning_module.automatic_optimization:\n\u001B[32m    343\u001B[39m     \u001B[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m344\u001B[39m     batch_output = \u001B[38;5;28mself\u001B[39m.automatic_optimization.run(trainer.optimizers[\u001B[32m0\u001B[39m], batch_idx, kwargs)\n\u001B[32m    345\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:185\u001B[39m, in \u001B[36m_AutomaticOptimization.run\u001B[39m\u001B[34m(self, optimizer, batch_idx, kwargs)\u001B[39m\n\u001B[32m    184\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m _block_parallel_sync_behavior(\u001B[38;5;28mself\u001B[39m.trainer.strategy, block=\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m185\u001B[39m         closure()\n\u001B[32m    187\u001B[39m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[32m    188\u001B[39m \u001B[38;5;66;03m# BACKWARD PASS\u001B[39;00m\n\u001B[32m    189\u001B[39m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[32m    190\u001B[39m \u001B[38;5;66;03m# gradient update with accumulated gradients\u001B[39;00m\n\u001B[32m    191\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:146\u001B[39m, in \u001B[36mClosure.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    144\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001B[32m--> \u001B[39m\u001B[32m146\u001B[39m     \u001B[38;5;28mself\u001B[39m._result = \u001B[38;5;28mself\u001B[39m.closure(*args, **kwargs)\n\u001B[32m    147\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._result.loss\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:140\u001B[39m, in \u001B[36mClosure.closure\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    139\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m step_output.closure_loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m140\u001B[39m     \u001B[38;5;28mself\u001B[39m._backward_fn(step_output.closure_loss)\n\u001B[32m    142\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:241\u001B[39m, in \u001B[36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001B[39m\u001B[34m(loss)\u001B[39m\n\u001B[32m    240\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mbackward_fn\u001B[39m(loss: Tensor) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m241\u001B[39m     call._call_strategy_hook(\u001B[38;5;28mself\u001B[39m.trainer, \u001B[33m\"\u001B[39m\u001B[33mbackward\u001B[39m\u001B[33m\"\u001B[39m, loss, optimizer)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:328\u001B[39m, in \u001B[36m_call_strategy_hook\u001B[39m\u001B[34m(trainer, hook_name, *args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m trainer.profiler.profile(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer.strategy.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m328\u001B[39m     output = fn(*args, **kwargs)\n\u001B[32m    330\u001B[39m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:213\u001B[39m, in \u001B[36mStrategy.backward\u001B[39m\u001B[34m(self, closure_loss, optimizer, *args, **kwargs)\u001B[39m\n\u001B[32m    211\u001B[39m closure_loss = \u001B[38;5;28mself\u001B[39m.precision_plugin.pre_backward(closure_loss, \u001B[38;5;28mself\u001B[39m.lightning_module)\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m \u001B[38;5;28mself\u001B[39m.precision_plugin.backward(closure_loss, \u001B[38;5;28mself\u001B[39m.lightning_module, optimizer, *args, **kwargs)\n\u001B[32m    215\u001B[39m closure_loss = \u001B[38;5;28mself\u001B[39m.precision_plugin.post_backward(closure_loss, \u001B[38;5;28mself\u001B[39m.lightning_module)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:73\u001B[39m, in \u001B[36mPrecision.backward\u001B[39m\u001B[34m(self, tensor, model, optimizer, *args, **kwargs)\u001B[39m\n\u001B[32m     62\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Performs the actual backpropagation.\u001B[39;00m\n\u001B[32m     63\u001B[39m \n\u001B[32m     64\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     71\u001B[39m \n\u001B[32m     72\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m model.backward(tensor, *args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1097\u001B[39m, in \u001B[36mLightningModule.backward\u001B[39m\u001B[34m(self, loss, *args, **kwargs)\u001B[39m\n\u001B[32m   1096\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1097\u001B[39m     loss.backward(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m torch.autograd.backward(\n\u001B[32m    649\u001B[39m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001B[32m    650\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m _engine_run_backward(\n\u001B[32m    354\u001B[39m     tensors,\n\u001B[32m    355\u001B[39m     grad_tensors_,\n\u001B[32m    356\u001B[39m     retain_graph,\n\u001B[32m    357\u001B[39m     create_graph,\n\u001B[32m    358\u001B[39m     inputs,\n\u001B[32m    359\u001B[39m     allow_unreachable=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    360\u001B[39m     accumulate_grad=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    361\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable._execution_engine.run_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    825\u001B[39m         t_outputs, *args, **kwargs\n\u001B[32m    826\u001B[39m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m      2\u001B[39m model_configs_rand = [\n\u001B[32m      3\u001B[39m     {\u001B[33m\"\u001B[39m\u001B[33mnum_classes\u001B[39m\u001B[33m\"\u001B[39m: num_classes,\n\u001B[32m      4\u001B[39m      \u001B[33m\"\u001B[39m\u001B[33mweight_decay\u001B[39m\u001B[33m\"\u001B[39m:  \u001B[32m0.05\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     11\u001B[39m      \u001B[33m\"\u001B[39m\u001B[33mckpt_path\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mnotebook/downstream/load_model/random-4en1de.pt\u001B[39m\u001B[33m\"\u001B[39m},\n\u001B[32m     12\u001B[39m ]\n\u001B[32m     13\u001B[39m set_seed(\u001B[32m42\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m train_finetune(model_configs_rand, early_stopping=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 38\u001B[39m, in \u001B[36mtrain_finetune\u001B[39m\u001B[34m(cfg, early_stopping)\u001B[39m\n\u001B[32m     26\u001B[39m     callbacks = [metrics_cb]\n\u001B[32m     28\u001B[39m trainer = pl.Trainer(\n\u001B[32m     29\u001B[39m     max_epochs=cfg[\u001B[33m'\u001B[39m\u001B[33mmax_epochs\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     30\u001B[39m     accelerator=\u001B[33m'\u001B[39m\u001B[33mgpu\u001B[39m\u001B[33m'\u001B[39m, devices=\u001B[32m1\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     35\u001B[39m     callbacks=callbacks\n\u001B[32m     36\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m trainer.fit(model, dm)\n\u001B[32m     39\u001B[39m test_res = trainer.test(model, dm)[\u001B[32m0\u001B[39m]\n\u001B[32m     41\u001B[39m model.test_results = test_res\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:561\u001B[39m, in \u001B[36mTrainer.fit\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    559\u001B[39m \u001B[38;5;28mself\u001B[39m.training = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    560\u001B[39m \u001B[38;5;28mself\u001B[39m.should_stop = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m561\u001B[39m call._call_and_handle_interrupt(\n\u001B[32m    562\u001B[39m     \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001B[32m    563\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:65\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     63\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(launcher, _SubprocessScriptLauncher):\n\u001B[32m     64\u001B[39m         launcher.kill(_get_sigkill_signal())\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m     exit(\u001B[32m1\u001B[39m)\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[32m     68\u001B[39m     _interrupt(trainer, exception)\n",
      "\u001B[31mNameError\u001B[39m: name 'exit' is not defined"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 Encoders - Pretrained\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T08:02:35.927775Z",
     "start_time": "2025-07-06T07:51:58.812926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_4en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/4en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_4en1de, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.735   Total estimated model params size (MB)\n",
      "80        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.6312684416770935\r\n",
      "         test_f1            0.5604722499847412\r\n",
      "        test_loss           1.3492323160171509\r\n",
      "     test_precision         0.6229105591773987\r\n",
      "       test_recall          0.5299901962280273\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250706_180233/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250706_180233\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6 Encoders - Random weights (scratch)\n",
    "\n",
    "Starting with same arch. as our pretrained 6 encoder model, just with random weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T09:13:34.108668Z",
     "start_time": "2025-07-06T09:03:45.956958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_rand_6 = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/random-6en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_rand_6, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "56.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "56.5 M    Total params\n",
      "226.141   Total estimated model params size (MB)\n",
      "136       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5103244781494141\r\n",
      "         test_f1            0.43657827377319336\r\n",
      "        test_loss            1.664811611175537\r\n",
      "     test_precision         0.5004916787147522\r\n",
      "       test_recall          0.40609636902809143\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250706_191333/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250706_191333\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6 Encoders - Pretrained"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T08:13:31.162881Z",
     "start_time": "2025-07-06T08:02:35.950886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model configurations\n",
    "model_configs_6en1de = [\n",
    "    {\"num_classes\": num_classes,\n",
    "     \"weight_decay\":  0.05,\n",
    "     \"backbone_lr\":   1e-5,\n",
    "     \"head_lr\":       1e-4,\n",
    "     \"backbone\": \"mae-ast\",\n",
    "     \"finetune\": True,\n",
    "     \"class_weights\": class_weights,\n",
    "     \"max_epochs\": 20,\n",
    "     \"ckpt_path\": \"notebook/downstream/load_model/6en1de.pt\"},\n",
    "]\n",
    "set_seed(42)\n",
    "train_finetune(model_configs_6en1de, early_stopping=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "56.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "56.5 M    Total params\n",
      "226.141   Total estimated model params size (MB)\n",
      "136       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.6784660816192627\r\n",
      "         test_f1            0.6057035326957703\r\n",
      "        test_loss            1.175337314605713\r\n",
      "     test_precision         0.6720747351646423\r\n",
      "       test_recall          0.5732546448707581\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250706_181330/\n",
      "Completed mae-ast (FT), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250706_181330\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
