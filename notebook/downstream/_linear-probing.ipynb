{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T05:31:33.294357Z",
     "start_time": "2025-07-13T05:31:33.288455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T05:31:43.174904Z",
     "start_time": "2025-07-13T05:31:34.211679Z"
    }
   },
   "cell_type": "code",
   "source": "from scripts.ft_lp import *",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\s3prl\\upstream\\byol_s\\byol_a\\common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "ESPnet is not installed, cannot use espnet_hubert upstream\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1017 examples, 31 classes\n",
      "  Clymene_Dolphin: 38\n",
      "  Bottlenose_Dolphin: 15\n",
      "  Spinner_Dolphin: 69\n",
      "  Beluga,_White_Whale: 30\n",
      "  Bearded_Seal: 22\n",
      "  Minke_Whale: 10\n",
      "  Humpback_Whale: 38\n",
      "  Southern_Right_Whale: 15\n",
      "  White-sided_Dolphin: 33\n",
      "  Narwhal: 30\n",
      "  White-beaked_Dolphin: 34\n",
      "  Northern_Right_Whale: 32\n",
      "  Frasers_Dolphin: 52\n",
      "  Grampus,_Rissos_Dolphin: 40\n",
      "  Harp_Seal: 28\n",
      "  Atlantic_Spotted_Dolphin: 35\n",
      "  Fin,_Finback_Whale: 30\n",
      "  Ross_Seal: 30\n",
      "  Rough-Toothed_Dolphin: 30\n",
      "  Killer_Whale: 21\n",
      "  Pantropical_Spotted_Dolphin: 40\n",
      "  Short-Finned_Pacific_Pilot_Whale: 40\n",
      "  Bowhead_Whale: 36\n",
      "  False_Killer_Whale: 35\n",
      "  Melon_Headed_Whale: 38\n",
      "  Long-Finned_Pilot_Whale: 42\n",
      "  Striped_Dolphin: 49\n",
      "  Leopard_Seal: 6\n",
      "  Walrus: 23\n",
      "  Sperm_Whale: 45\n",
      "  Common_Dolphin: 31\n",
      "Validation dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 12\n",
      "  Bottlenose_Dolphin: 5\n",
      "  Spinner_Dolphin: 23\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 7\n",
      "  Minke_Whale: 4\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 11\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 18\n",
      "  Grampus,_Rissos_Dolphin: 13\n",
      "  Harp_Seal: 9\n",
      "  Atlantic_Spotted_Dolphin: 12\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 13\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 13\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 8\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 10\n",
      "Test dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 13\n",
      "  Bottlenose_Dolphin: 4\n",
      "  Spinner_Dolphin: 22\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 8\n",
      "  Minke_Whale: 3\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 12\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 17\n",
      "  Grampus,_Rissos_Dolphin: 14\n",
      "  Harp_Seal: 10\n",
      "  Atlantic_Spotted_Dolphin: 11\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 14\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 12\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 7\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 11\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:20:12.580167Z",
     "start_time": "2025-07-12T09:20:12.521123Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.getcwd())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T05:31:43.240894Z",
     "start_time": "2025-07-13T05:31:43.234501Z"
    }
   },
   "cell_type": "code",
   "source": "seeds = [42, 1337, 2025, 31415, 27182]",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Linear Probing**\n",
    "Freezing the backbone and using a linear classifier head"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Encoder Scratch - LP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T05:16:21.964352Z",
     "start_time": "2025-07-13T02:56:44.104359Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-seed run at: 2025-07-13 12:56:44\n",
      "Running for seeds: [42]\n",
      "\n",
      "--- Running with Seed: 42 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "21.9 M    Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.45427727699279785\r\n",
      "         test_f1            0.3962634205818176\r\n",
      "        test_loss           1.9653288125991821\r\n",
      "     test_precision         0.44641098380088806\r\n",
      "       test_recall          0.37118977308273315\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_151621/\n",
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_151621\n",
      "\n",
      "--- All training runs completed. ---\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "model_name = '2en1de scratch - lp'\n",
    "log_directory = \"lightning_logs\"\n",
    "run_start_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Starting multi-seed run at: {run_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Running for seeds: {seeds}\\n\")\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"--- Running with Seed: {seed} ---\")\n",
    "\n",
    "    model_configs_2en1de_lp = [\n",
    "        {\"num_classes\": num_classes,\n",
    "         \"weight_decay\":  0.05,\n",
    "         \"backbone_lr\": 1e-4,\n",
    "         \"head_lr\": 1e-4,\n",
    "         \"backbone\": \"mae-ast\",\n",
    "         \"finetune\": False,\n",
    "         \"class_weights\": class_weights,\n",
    "         \"max_epochs\": 100,\n",
    "         \"ckpt_path\": f\"notebook/downstream/load_model/random-2en1de-seed{seed}.pt\"},\n",
    "    ]\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_finetune(model_configs_2en1de_lp, early_stopping=False)\n",
    "\n",
    "print(\"\\n--- All training runs completed. ---\")\n",
    "\n",
    "aggregate_metrics(model_name, log_directory, run_start_time)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 Encoder - LP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T07:01:03.074562Z",
     "start_time": "2025-07-12T03:39:10.953908Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-seed run at: 2025-07-12 13:39:10\n",
      "Running for seeds: [42, 1337, 2025, 31415, 27182]\n",
      "\n",
      "--- Running with Seed: 42 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "21.9 M    Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5663716793060303\r\n",
      "         test_f1            0.5063915252685547\r\n",
      "        test_loss           1.4470789432525635\r\n",
      "     test_precision         0.5599803328514099\r\n",
      "       test_recall          0.4803343415260315\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250712_142203/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250712_142203\n",
      "--- Running with Seed: 1337 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "21.9 M    Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5781710743904114\r\n",
      "         test_f1            0.5142577886581421\r\n",
      "        test_loss           1.4592058658599854\r\n",
      "     test_precision         0.5707964897155762\r\n",
      "       test_recall          0.48672565817832947\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250712_150142/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250712_150142\n",
      "--- Running with Seed: 2025 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "21.9 M    Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5781710743904114\r\n",
      "         test_f1            0.5181909799575806\r\n",
      "        test_loss            1.458221197128296\r\n",
      "     test_precision         0.5727630257606506\r\n",
      "       test_recall          0.4916420578956604\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250712_154127/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 31415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250712_154127\n",
      "--- Running with Seed: 31415 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "21.9 M    Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5870206356048584\r\n",
      "         test_f1            0.5260571837425232\r\n",
      "        test_loss           1.4848449230194092\r\n",
      "     test_precision         0.5830875039100647\r\n",
      "       test_recall          0.49754175543785095\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250712_162115/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 27182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250712_162115\n",
      "--- Running with Seed: 27182 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 21.9 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "21.9 M    Non-trainable params\n",
      "22.1 M    Total params\n",
      "88.249    Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5634218454360962\r\n",
      "         test_f1             0.502458393573761\r\n",
      "        test_loss            1.456678032875061\r\n",
      "     test_precision         0.5580137372016907\r\n",
      "       test_recall          0.4754178524017334\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250712_170102/\n",
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250712_170102\n",
      "\n",
      "--- All training runs completed. ---\n",
      "\n",
      "Aggregating results from 'lightning_logs'...\n",
      "Found 5 relevant log files to aggregate.\n",
      "\n",
      "Aggregated results saved to 'notebook/downstream/ft_lp_results/_aggregate results/2en1de - lp-mean.csv' and 'notebook/downstream/ft_lp_results/_aggregate results/2en1de - lp-std.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\scripts\\ft_lp.py:721: RuntimeWarning: Mean of empty slice\n",
      "  mean_data = np.nanmean(stacked_data, axis=0)\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "execution_count": 15,
   "source": [
    "model_name = '2en1de - lp'\n",
    "log_directory = \"lightning_logs\"\n",
    "run_start_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Starting multi-seed run at: {run_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Running for seeds: {seeds}\\n\")\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"--- Running with Seed: {seed} ---\")\n",
    "\n",
    "    model_configs_2en1de_lp = [\n",
    "        {\"num_classes\": num_classes,\n",
    "         \"weight_decay\":  0.05,\n",
    "         \"backbone_lr\": 1e-4,\n",
    "         \"head_lr\": 1e-4,\n",
    "         \"backbone\": \"mae-ast\",\n",
    "         \"finetune\": False,\n",
    "         \"class_weights\": class_weights,\n",
    "         \"max_epochs\": 100,\n",
    "         \"ckpt_path\": \"notebook/downstream/load_model/2en1de.pt\"},\n",
    "    ]\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_finetune(model_configs_2en1de_lp, early_stopping=False)\n",
    "\n",
    "print(\"\\n--- All training runs completed. ---\")\n",
    "\n",
    "aggregate_metrics(model_name, log_directory, run_start_time)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 Encoder Scratch - LP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T23:12:08.525545Z",
     "start_time": "2025-07-12T17:01:54.900004Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_name = '4en1de scratch - lp'\n",
    "log_directory = \"lightning_logs\"\n",
    "run_start_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Starting multi-seed run at: {run_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Running for seeds: {seeds}\\n\")\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"--- Running with Seed: {seed} ---\")\n",
    "\n",
    "    model_configs_4en1de_lp = [\n",
    "        {\"num_classes\": num_classes,\n",
    "         \"weight_decay\":  0.05,\n",
    "         \"backbone_lr\": 1e-4,\n",
    "         \"head_lr\": 1e-4,\n",
    "         \"backbone\": \"mae-ast\",\n",
    "         \"finetune\": False,\n",
    "         \"class_weights\": class_weights,\n",
    "         \"max_epochs\": 100,\n",
    "         \"ckpt_path\": f\"notebook/downstream/load_model/random-4en1de-seed{seed}.pt\"},\n",
    "    ]\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_finetune(model_configs_4en1de_lp, early_stopping=False)\n",
    "\n",
    "print(\"\\n--- All training runs completed. ---\")\n",
    "\n",
    "aggregate_metrics(model_name, log_directory, run_start_time)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4 Encoder - LP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T12:16:24.991321Z",
     "start_time": "2025-07-12T12:16:24.956777Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregating results from 'lightning_logs'...\n",
      "Found 5 relevant log files to aggregate.\n",
      "\n",
      "Aggregated results saved to 'notebook/downstream/ft_lp_results/_aggregate results/4en1de - lp-mean.csv' and 'notebook/downstream/ft_lp_results/_aggregate results/4en1de - lp-std.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\scripts\\ft_lp.py:722: RuntimeWarning: Mean of empty slice\n",
      "  mean_data = np.nanmean(stacked_data, axis=0)\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "model_name = '4en1de - lp'\n",
    "log_directory = \"lightning_logs\"\n",
    "run_start_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Starting multi-seed run at: {run_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Running for seeds: {seeds}\\n\")\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"--- Running with Seed: {seed} ---\")\n",
    "\n",
    "    model_configs_4en1de_lp = [\n",
    "        {\"num_classes\": num_classes,\n",
    "         \"weight_decay\":  0.05,\n",
    "         \"backbone_lr\": 1e-4,\n",
    "         \"head_lr\": 1e-4,\n",
    "         \"backbone\": \"mae-ast\",\n",
    "         \"finetune\": False,\n",
    "         \"class_weights\": class_weights,\n",
    "         \"max_epochs\": 100,\n",
    "         \"ckpt_path\": \"notebook/downstream/load_model/4en1de.pt\"},\n",
    "    ]\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_finetune(model_configs_4en1de_lp, early_stopping=False)\n",
    "\n",
    "print(\"\\n--- All training runs completed. ---\")\n",
    "\n",
    "aggregate_metrics(model_name, log_directory, run_start_time)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6 Encoder Scratch - LP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T23:12:08.525545Z",
     "start_time": "2025-07-12T17:01:54.900004Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-seed run at: 2025-07-13 03:01:54\n",
      "Running for seeds: [42, 1337, 2025, 31415, 27182]\n",
      "\n",
      "--- Running with Seed: 42 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.4690265357494354\r\n",
      "         test_f1            0.41494593024253845\r\n",
      "        test_loss           1.9642887115478516\r\n",
      "     test_precision         0.4641101062297821\r\n",
      "       test_recall          0.39036381244659424\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_041633/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_041633\n",
      "--- Running with Seed: 1337 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.4572271406650543\r\n",
      "         test_f1            0.40216317772865295\r\n",
      "        test_loss            1.954016923904419\r\n",
      "     test_precision         0.45034417510032654\r\n",
      "       test_recall          0.37807273864746094\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_053124/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_053124\n",
      "--- Running with Seed: 2025 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.46607670187950134\r\n",
      "         test_f1            0.41101276874542236\r\n",
      "        test_loss           1.9706093072891235\r\n",
      "     test_precision         0.4601770043373108\r\n",
      "       test_recall          0.38643068075180054\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_064602/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 31415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_064602\n",
      "--- Running with Seed: 31415 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.44247788190841675\r\n",
      "         test_f1            0.38544726371765137\r\n",
      "        test_loss           1.9634805917739868\r\n",
      "     test_precision         0.43559491634368896\r\n",
      "       test_recall          0.3603736162185669\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_080038/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 27182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_080038\n",
      "--- Running with Seed: 27182 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.4808259606361389\r\n",
      "         test_f1            0.4208456873893738\r\n",
      "        test_loss           1.9361788034439087\r\n",
      "     test_precision         0.4729596674442291\r\n",
      "       test_recall          0.39478859305381775\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_091208/\n",
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_091208\n",
      "\n",
      "--- All training runs completed. ---\n",
      "\n",
      "Aggregating results from 'lightning_logs'...\n",
      "Found 5 relevant log files to aggregate.\n",
      "\n",
      "Aggregated results saved to 'notebook/downstream/ft_lp_results/_aggregate results/6en1de scratch - lp-mean.csv' and 'notebook/downstream/ft_lp_results/_aggregate results/6en1de scratch - lp-std.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\scripts\\ft_lp.py:721: RuntimeWarning: Mean of empty slice\n",
      "  mean_data = np.nanmean(stacked_data, axis=0)\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "execution_count": 5,
   "source": [
    "model_name = '6en1de scratch - lp'\n",
    "log_directory = \"lightning_logs\"\n",
    "run_start_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Starting multi-seed run at: {run_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Running for seeds: {seeds}\\n\")\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"--- Running with Seed: {seed} ---\")\n",
    "\n",
    "    model_configs_6en1de_lp = [\n",
    "        {\"num_classes\": num_classes,\n",
    "         \"weight_decay\":  0.05,\n",
    "         \"backbone_lr\": 1e-4,\n",
    "         \"head_lr\": 1e-4,\n",
    "         \"backbone\": \"mae-ast\",\n",
    "         \"finetune\": False,\n",
    "         \"class_weights\": class_weights,\n",
    "         \"max_epochs\": 100,\n",
    "         \"ckpt_path\": f\"notebook/downstream/load_model/random-6en1de-seed{seed}.pt\"},\n",
    "    ]\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_finetune(model_configs_6en1de_lp, early_stopping=False)\n",
    "\n",
    "print(\"\\n--- All training runs completed. ---\")\n",
    "\n",
    "aggregate_metrics(model_name, log_directory, run_start_time)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6 Encoder - LP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T17:01:54.838774Z",
     "start_time": "2025-07-12T12:24:17.819135Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-seed run at: 2025-07-12 22:24:17\n",
      "Running for seeds: [1337, 2025, 31415, 27182]\n",
      "\n",
      "--- Running with Seed: 1337 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.6017699241638184\r\n",
      "         test_f1             0.543756365776062\r\n",
      "        test_loss           1.4345768690109253\r\n",
      "     test_precision          0.596853494644165\r\n",
      "       test_recall          0.5172074437141418\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250712_233002/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250712_233002\n",
      "--- Running with Seed: 2025 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5840708017349243\r\n",
      "         test_f1            0.5260571837425232\r\n",
      "        test_loss           1.4364423751831055\r\n",
      "     test_precision         0.5781710743904114\r\n",
      "       test_recall                  0.5\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_003707/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 31415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_003707\n",
      "--- Running with Seed: 31415 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5958701968193054\r\n",
      "         test_f1            0.5437563061714172\r\n",
      "        test_loss           1.4300569295883179\r\n",
      "     test_precision         0.5919370651245117\r\n",
      "       test_recall          0.5196656584739685\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_014724/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 27182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_014724\n",
      "--- Running with Seed: 27182 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | UpstreamExpert      | 50.2 M | train\n",
      "1  | classifier      | Sequential          | 202 K  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "202 K     Trainable params\n",
      "50.2 M    Non-trainable params\n",
      "50.4 M    Total params\n",
      "201.655   Total estimated model params size (MB)\n",
      "130       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.6047197580337524\r\n",
      "         test_f1            0.5457229614257812\r\n",
      "        test_loss           1.4121935367584229\r\n",
      "     test_precision         0.5998033285140991\r\n",
      "       test_recall          0.5186823606491089\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\mae-ast_imbalance\\20250713_030154/\n",
      "Completed mae-ast (Frozen), artifacts in notebook\\downstream\\model\\mae-ast_imbalance\\20250713_030154\n",
      "\n",
      "--- All training runs completed. ---\n",
      "\n",
      "Aggregating results from 'lightning_logs'...\n",
      "Found 5 relevant log files to aggregate.\n",
      "\n",
      "Aggregated results saved to 'notebook/downstream/ft_lp_results/_aggregate results/6en1de - lp-mean.csv' and 'notebook/downstream/ft_lp_results/_aggregate results/6en1de - lp-std.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\scripts\\ft_lp.py:721: RuntimeWarning: Mean of empty slice\n",
      "  mean_data = np.nanmean(stacked_data, axis=0)\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "model_name = '6en1de - lp'\n",
    "log_directory = \"lightning_logs\"\n",
    "run_start_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Starting multi-seed run at: {run_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Running for seeds: {seeds}\\n\")\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"--- Running with Seed: {seed} ---\")\n",
    "\n",
    "    model_configs_6en1de_lp = [\n",
    "        {\"num_classes\": num_classes,\n",
    "         \"weight_decay\":  0.05,\n",
    "         \"backbone_lr\": 1e-4,\n",
    "         \"head_lr\": 1e-4,\n",
    "         \"backbone\": \"mae-ast\",\n",
    "         \"finetune\": False,\n",
    "         \"class_weights\": class_weights,\n",
    "         \"max_epochs\": 100,\n",
    "         \"ckpt_path\": \"notebook/downstream/load_model/6en1de.pt\"},\n",
    "    ]\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_finetune(model_configs_6en1de_lp, early_stopping=False)\n",
    "\n",
    "print(\"\\n--- All training runs completed. ---\")\n",
    "\n",
    "aggregate_metrics(model_name, log_directory, run_start_time)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wav2Vec - LP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:43:28.458095Z",
     "start_time": "2025-07-13T05:32:14.258470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'wav2vec - lp'\n",
    "log_directory = \"lightning_logs\"\n",
    "run_start_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Starting multi-seed run at: {run_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Running for seeds: {seeds}\\n\")\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"--- Running with Seed: {seed} ---\")\n",
    "\n",
    "    model_configs_w2v_lp = [\n",
    "        {\"num_classes\": num_classes,\n",
    "         \"weight_decay\":  0.05,\n",
    "         \"backbone_lr\": 1e-4,\n",
    "         \"head_lr\": 1e-4,\n",
    "         \"backbone\": \"facebook/wav2vec2-base\",\n",
    "         \"finetune\": False,\n",
    "         \"class_weights\": class_weights,\n",
    "         \"max_epochs\": 100,\n",
    "         \"ckpt_path\": \"notebook/downstream/load_model/6en1de.pt\"},\n",
    "    ]\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_finetune(model_configs_w2v_lp, early_stopping=False)\n",
    "\n",
    "print(\"\\n--- All training runs completed. ---\")\n",
    "\n",
    "aggregate_metrics(model_name, log_directory, run_start_time)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-seed run at: 2025-07-13 15:32:14\n",
      "Running for seeds: [42, 1337, 2025, 31415, 27182]\n",
      "\n",
      "--- Running with Seed: 42 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\transformers\\configuration_utils.py:309: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | Wav2Vec2Model       | 94.4 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "94.4 M    Non-trainable params\n",
      "94.4 M    Total params\n",
      "377.588   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "220       Modules in eval mode\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc             0.501474916934967\r\n",
      "         test_f1            0.4306785464286804\r\n",
      "        test_loss           1.9002667665481567\r\n",
      "     test_precision         0.49754175543785095\r\n",
      "       test_recall           0.397246778011322\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_155823/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed facebook/wav2vec2-base (Frozen), artifacts in notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_155823\n",
      "--- Running with Seed: 1337 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | Wav2Vec2Model       | 94.4 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "94.4 M    Non-trainable params\n",
      "94.4 M    Total params\n",
      "377.588   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "220       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc             0.50737464427948\r\n",
      "         test_f1            0.4326450824737549\r\n",
      "        test_loss           1.9112552404403687\r\n",
      "     test_precision         0.5024581551551819\r\n",
      "       test_recall          0.39773842692375183\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_162425/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed facebook/wav2vec2-base (Frozen), artifacts in notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_162425\n",
      "--- Running with Seed: 2025 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | Wav2Vec2Model       | 94.4 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "94.4 M    Non-trainable params\n",
      "94.4 M    Total params\n",
      "377.588   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "220       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.49852508306503296\r\n",
      "         test_f1            0.4208456873893738\r\n",
      "        test_loss           1.8913347721099854\r\n",
      "     test_precision         0.4916420578956604\r\n",
      "       test_recall          0.38544735312461853\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_165030/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 31415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed facebook/wav2vec2-base (Frozen), artifacts in notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_165030\n",
      "--- Running with Seed: 31415 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | Wav2Vec2Model       | 94.4 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "94.4 M    Non-trainable params\n",
      "94.4 M    Total params\n",
      "377.588   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "220       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.48967552185058594\r\n",
      "         test_f1            0.4188791513442993\r\n",
      "        test_loss           1.9255645275115967\r\n",
      "     test_precision         0.4827924966812134\r\n",
      "       test_recall          0.38692229986190796\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_171701/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 27182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed facebook/wav2vec2-base (Frozen), artifacts in notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_171701\n",
      "--- Running with Seed: 27182 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | Wav2Vec2Model       | 94.4 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "94.4 M    Non-trainable params\n",
      "94.4 M    Total params\n",
      "377.588   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "220       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.49852508306503296\r\n",
      "         test_f1            0.42674538493156433\r\n",
      "        test_loss            1.878953218460083\r\n",
      "     test_precision         0.49262532591819763\r\n",
      "       test_recall          0.39380529522895813\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_174328/\n",
      "Completed facebook/wav2vec2-base (Frozen), artifacts in notebook\\downstream\\model\\facebook_wav2vec2-base_imbalance\\20250713_174328\n",
      "\n",
      "--- All training runs completed. ---\n",
      "\n",
      "Aggregating results from 'lightning_logs'...\n",
      "Found 5 relevant log files to aggregate.\n",
      "\n",
      "Aggregated results saved to 'notebook/downstream/ft_lp_results/_aggregate results/wav2vec - lp-mean.csv' and 'notebook/downstream/ft_lp_results/_aggregate results/wav2vec - lp-std.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\scripts\\ft_lp.py:721: RuntimeWarning: Mean of empty slice\n",
      "  mean_data = np.nanmean(stacked_data, axis=0)\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ImageNet - LP"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T10:44:50.752595Z",
     "start_time": "2025-07-13T07:43:28.485363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'imagenet - lp'\n",
    "log_directory = \"lightning_logs\"\n",
    "run_start_time = datetime.datetime.now()\n",
    "\n",
    "print(f\"Starting multi-seed run at: {run_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Running for seeds: {seeds}\\n\")\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"--- Running with Seed: {seed} ---\")\n",
    "\n",
    "    model_configs_imagenet_lp = [\n",
    "        {\"num_classes\": num_classes,\n",
    "         \"weight_decay\":  0.05,\n",
    "         \"backbone_lr\":   1e-4,\n",
    "         \"head_lr\":       1e-4,\n",
    "         \"backbone\": \"vit-imagenet\",\n",
    "         \"n_mels\": 128,\n",
    "         \"target_size\": 224,\n",
    "         \"finetune\": False,\n",
    "         \"class_weights\": class_weights,\n",
    "         \"max_epochs\": 100,\n",
    "         \"ckpt_path\": \"notebook/downstream/load_model/6en1de.pt\"},\n",
    "    ]\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_finetune(model_configs_imagenet_lp, early_stopping=False)\n",
    "\n",
    "print(\"\\n--- All training runs completed. ---\")\n",
    "\n",
    "aggregate_metrics(model_name, log_directory, run_start_time)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-seed run at: 2025-07-13 17:43:28\n",
      "Running for seeds: [42, 1337, 2025, 31415, 27182]\n",
      "\n",
      "--- Running with Seed: 42 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:30: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | ViTModel            | 85.8 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.296   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "212       Modules in eval mode\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5752212405204773\r\n",
      "         test_f1             0.511307954788208\r\n",
      "        test_loss           1.6076768636703491\r\n",
      "     test_precision         0.5683382153511047\r\n",
      "       test_recall          0.4827924966812134\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_182036/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed vit-imagenet (Frozen), artifacts in notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_182036\n",
      "--- Running with Seed: 1337 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | ViTModel            | 85.8 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.296   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "212       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5634218454360962\r\n",
      "         test_f1            0.4916422367095947\r\n",
      "        test_loss           1.6026726961135864\r\n",
      "     test_precision          0.555555522441864\r\n",
      "       test_recall          0.4596853256225586\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_185644/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed vit-imagenet (Frozen), artifacts in notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_185644\n",
      "--- Running with Seed: 2025 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | ViTModel            | 85.8 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.296   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "212       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5604719519615173\r\n",
      "         test_f1            0.49164217710494995\r\n",
      "        test_loss           1.5827629566192627\r\n",
      "     test_precision         0.5516223907470703\r\n",
      "       test_recall          0.46165192127227783\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_193253/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 31415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed vit-imagenet (Frozen), artifacts in notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_193253\n",
      "--- Running with Seed: 31415 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | ViTModel            | 85.8 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.296   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "212       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5929203629493713\r\n",
      "         test_f1            0.5250739455223083\r\n",
      "        test_loss           1.5620557069778442\r\n",
      "     test_precision         0.5835791230201721\r\n",
      "       test_recall          0.4965584874153137\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_200848/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 27182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed vit-imagenet (Frozen), artifacts in notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_200848\n",
      "--- Running with Seed: 27182 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTModel: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | ViTModel            | 85.8 M | eval \n",
      "1  | classifier      | Sequential          | 25.4 K | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.296   Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "212       Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.5693215131759644\r\n",
      "         test_f1            0.49754202365875244\r\n",
      "        test_loss           1.5632028579711914\r\n",
      "     test_precision         0.5599803924560547\r\n",
      "       test_recall          0.46705999970436096\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_204450/\n",
      "Completed vit-imagenet (Frozen), artifacts in notebook\\downstream\\model\\vit-imagenet_imbalance\\20250713_204450\n",
      "\n",
      "--- All training runs completed. ---\n",
      "\n",
      "Aggregating results from 'lightning_logs'...\n",
      "Found 5 relevant log files to aggregate.\n",
      "\n",
      "Aggregated results saved to 'notebook/downstream/ft_lp_results/_aggregate results/imagenet - lp-mean.csv' and 'notebook/downstream/ft_lp_results/_aggregate results/imagenet - lp-std.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\OneDrive - Georgia Institute of Technology\\25-5 Summer\\CS 7643 - Deep Learning\\_Project\\mbari-mae\\scripts\\ft_lp.py:721: RuntimeWarning: Mean of empty slice\n",
      "  mean_data = np.nanmean(stacked_data, axis=0)\n",
      "C:\\Users\\Ali\\miniconda3\\envs\\new25\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
