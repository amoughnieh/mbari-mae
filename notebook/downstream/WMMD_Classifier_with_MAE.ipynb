{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqEAfZZYIaiX"
      },
      "outputs": [],
      "source": [
        "# Standard library\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# Numerical computing\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Hugging Face Transformers\n",
        "from transformers import (\n",
        "    Wav2Vec2FeatureExtractor,\n",
        "    Wav2Vec2Model,\n",
        ")\n",
        "\n",
        "# Datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
        "\n",
        "# Metrics\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torchmetrics.classification import (\n",
        "    MulticlassF1Score,\n",
        "    MulticlassPrecision,\n",
        "    MulticlassRecall,\n",
        ")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MAE-AST Library\n",
        "from s3prl.nn.upstream import S3PRLUpstream\n",
        "\n",
        "# Fix the length of the input audio to the same length\n",
        "def _match_length_force(self, xs, target_max_len):\n",
        "    xs_max_len = xs.size(1)\n",
        "    if xs_max_len > target_max_len:\n",
        "        xs = xs[:, :target_max_len, :]\n",
        "    elif xs_max_len < target_max_len:\n",
        "        pad_len = target_max_len - xs_max_len\n",
        "        xs = torch.cat(\n",
        "            (xs, xs[:, -1:, :].repeat(1, pad_len, 1)),\n",
        "            dim=1\n",
        "        )\n",
        "    return xs\n",
        "\n",
        "S3PRLUpstream._match_length = _match_length_force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5aQ8ZsGkD7s"
      },
      "outputs": [],
      "source": [
        "# loading the dataset\n",
        "data_dir = \"data/watkins\"\n",
        "annotations_file_train = os.path.join(data_dir, \"annotations.train.csv\")\n",
        "annotations_file_valid = os.path.join(data_dir, \"annotations.valid.csv\")\n",
        "annotations_file_test = os.path.join(data_dir, \"annotations.test.csv\")\n",
        "\n",
        "ds = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\"train\": annotations_file_train,\n",
        "                \"validation\": annotations_file_valid,\n",
        "                \"test\": annotations_file_test},\n",
        ")\n",
        "\n",
        "for split_name in [\"train\", \"validation\", \"test\"]:\n",
        "    split_dataset = ds[split_name]\n",
        "    labels = split_dataset[\"label\"]\n",
        "    total = len(labels)\n",
        "    counts = Counter(labels)\n",
        "\n",
        "    print(f\"{split_name.capitalize()} dataset: {total} examples, {len(counts)} classes\")\n",
        "    if \"label\" in split_dataset.features and hasattr(split_dataset.features[\"label\"], \"names\"):\n",
        "        class_names = split_dataset.features[\"label\"].names\n",
        "        for idx, name in enumerate(class_names):\n",
        "            print(f\"  {idx} ({name}): {counts.get(name, 0)}\")\n",
        "    else:\n",
        "        for label, count in counts.items():\n",
        "            print(f\"  {label}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class weights calculation\n",
        "train_labels = ds[\"train\"][\"label\"]\n",
        "unique_labels = sorted(set(train_labels))\n",
        "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "y_train = [label_to_int[lbl] for lbl in train_labels]\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.arange(len(unique_labels)),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "num_classes = len(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6JYR66KeIUsg"
      },
      "outputs": [],
      "source": [
        "# model definition\n",
        "class WMMDClassifier(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int,\n",
        "        lr: float = 1e-3,\n",
        "        backbone: str = \"facebook/wav2vec2-base\",\n",
        "        ckpt_path: str = \"\",\n",
        "        finetune: bool = False,\n",
        "        class_weights=None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        if backbone == \"facebook/wav2vec2-base\":\n",
        "            self.backbone     = Wav2Vec2Model.from_pretrained(backbone)\n",
        "            self.embedding_dim = self.backbone.config.hidden_size\n",
        "        \n",
        "        elif backbone.lower() == \"mae-ast\":\n",
        "            up_kwargs = {\"name\": \"mae_ast_patch\"}\n",
        "            s3 = S3PRLUpstream(**up_kwargs)\n",
        "\n",
        "            enc = s3.upstream.model.encoder\n",
        "            enc.layers = nn.ModuleList(list(enc.layers)[:4])\n",
        "            s3.upstream.model.dec_sine_pos_embed = None\n",
        "            s3.upstream.model.decoder = None\n",
        "            s3.upstream.model.final_proj_reconstruction = None\n",
        "            s3.upstream.model.final_proj_classification  = None\n",
        "\n",
        "            new_n = len(enc.layers)\n",
        "            s3._num_layers       = new_n\n",
        "            s3._hidden_sizes     = s3._hidden_sizes[:new_n]\n",
        "            s3._downsample_rates = s3._downsample_rates[:new_n]\n",
        "\n",
        "            self.backbone      = s3\n",
        "            self.embedding_dim = s3.hidden_sizes[-1]\n",
        "\n",
        "            # Load the checkpoint for mae ast\n",
        "            if ckpt_path:\n",
        "                self.load_mae_ckpt(ckpt_path)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported backbone '{backbone}'\")\n",
        "\n",
        "        try:\n",
        "            self.backbone.gradient_checkpointing_enable()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = finetune\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(self.embedding_dim, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, num_classes),\n",
        "        )\n",
        "\n",
        "        if class_weights is not None:\n",
        "            cw = torch.tensor(class_weights, dtype=torch.float)\n",
        "            self.criterion = nn.CrossEntropyLoss(weight=cw)\n",
        "        else:\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        metrics_kwargs = dict(num_classes=num_classes, average='macro')\n",
        "        self.train_precision = MulticlassPrecision(**metrics_kwargs)\n",
        "        self.train_recall = MulticlassRecall(**metrics_kwargs)\n",
        "        self.train_f1 = MulticlassF1Score(**metrics_kwargs)\n",
        "        self.val_precision = MulticlassPrecision(**metrics_kwargs)\n",
        "        self.val_recall = MulticlassRecall(**metrics_kwargs)\n",
        "        self.val_f1 = MulticlassF1Score(**metrics_kwargs)\n",
        "        self.test_precision = MulticlassPrecision(**metrics_kwargs)\n",
        "        self.test_recall = MulticlassRecall(**metrics_kwargs)\n",
        "        self.test_f1 = MulticlassF1Score(**metrics_kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        bname = self.hparams.backbone.lower()\n",
        "        if bname == \"facebook/wav2vec2-base\":\n",
        "            out = self.backbone(x)\n",
        "            hidden = out.last_hidden_state\n",
        "        elif bname == \"mae-ast\":\n",
        "            if x.dim() == 3:\n",
        "                x = x.squeeze(-1)\n",
        "            wav_lens = torch.full((x.size(0),), x.size(1),\n",
        "                                dtype=torch.long, device=x.device)\n",
        "            all_hs, _ = self.backbone(x, wav_lens)\n",
        "            hidden   = all_hs[-1]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported backbone in forward(): '{self.hparams.backbone}'\")\n",
        "\n",
        "        emb = hidden.mean(dim=1)\n",
        "        return self.classifier(emb)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        self.log_batch_metrics(loss, preds, y, prefix='train')\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        self.log_batch_metrics(loss, preds, y, prefix='val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        self.log_batch_metrics(loss, preds, y, prefix='test')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
        "\n",
        "    def log_batch_metrics(self, loss, preds, targets, prefix):\n",
        "        self.log(f'{prefix}_loss', loss, prog_bar=True, on_epoch=True)\n",
        "        acc = (preds == targets).float().mean()\n",
        "        self.log(f'{prefix}_acc', acc, prog_bar=True, on_epoch=True)\n",
        "        precision = getattr(self, f'{prefix}_precision')(preds, targets)\n",
        "        recall = getattr(self, f'{prefix}_recall')(preds, targets)\n",
        "        f1 = getattr(self, f'{prefix}_f1')(preds, targets)\n",
        "        self.log(f'{prefix}_precision', precision, on_epoch=True)\n",
        "        self.log(f'{prefix}_recall', recall, on_epoch=True)\n",
        "        self.log(f'{prefix}_f1', f1, on_epoch=True)\n",
        "\n",
        "    def on_train_end(self):\n",
        "        save_dir = getattr(self, 'save_dir', None)\n",
        "        if save_dir:\n",
        "            self.save_model(save_dir)\n",
        "\n",
        "    def save_model(self):\n",
        "        base_dir = 'model'\n",
        "        bn = self.hparams.backbone.replace('/', '_')\n",
        "        cw = getattr(self.hparams, 'class_weights', None)\n",
        "        balance_flag = 'imbalance' if cw is not None else 'balance'\n",
        "        timestamp = getattr(self, 'finish_time', datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "        folder = os.path.join(base_dir, f\"{bn}_{balance_flag}\", timestamp)\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "        ckpt_path = os.path.join(folder, f\"{timestamp}.pt\")\n",
        "        payload = {\n",
        "            'state_dict': self.state_dict(),\n",
        "            'hparams': dict(self.hparams)\n",
        "        }\n",
        "        for attr in ('test_results', 'finish_time', 'epochs_trained'):\n",
        "            if hasattr(self, attr):\n",
        "                payload[attr] = getattr(self, attr)\n",
        "        torch.save(payload, ckpt_path)\n",
        "\n",
        "        stats_path = os.path.join(folder, f\"{timestamp}.txt\")\n",
        "        raw_hparams = dict(self.hparams)\n",
        "        serializable_hparams = {}\n",
        "        for k, v in raw_hparams.items():\n",
        "            if isinstance(v, np.ndarray):\n",
        "                serializable_hparams[k] = v.tolist()\n",
        "            elif isinstance(v, torch.Tensor):\n",
        "                serializable_hparams[k] = v.cpu().item() if v.ndim == 0 else v.cpu().tolist()\n",
        "            else:\n",
        "                serializable_hparams[k] = v\n",
        "\n",
        "        serializable_results = {}\n",
        "        if hasattr(self, 'test_results'):\n",
        "            for k, v in self.test_results.items():\n",
        "                serializable_results[k] = v.cpu().item() if isinstance(v, torch.Tensor) else v\n",
        "\n",
        "        with open(stats_path, 'w') as f:\n",
        "            f.write(f\"Model architecture:\\n{self}\\n\\n\")\n",
        "            f.write(\"Hyperparameters:\\n\")\n",
        "            f.write(json.dumps(serializable_hparams, indent=4))\n",
        "            f.write(\"\\n\\n\")\n",
        "            if serializable_results:\n",
        "                f.write(\"Test results:\\n\")\n",
        "                f.write(json.dumps(serializable_results, indent=4))\n",
        "                f.write(\"\\n\\n\")\n",
        "            if hasattr(self, 'epochs_trained'):\n",
        "                f.write(f\"Epochs trained: {self.epochs_trained}\\n\")\n",
        "\n",
        "        self._last_save_dir = folder\n",
        "        self._last_timestamp = timestamp\n",
        "        print(f\"Artifacts saved to {folder}/\")\n",
        "    \n",
        "    def load_mae_ckpt(self, ckpt_source: str):\n",
        "        \"\"\"\n",
        "        Load MAE-AST checkpoint into the truncated upstream model\n",
        "        and verify exact weight equality for each loaded parameter.\n",
        "        \"\"\"\n",
        "        loaded = torch.load(ckpt_source)\n",
        "        state_dict = loaded.get('model', loaded)\n",
        "\n",
        "        up = self.backbone.upstream.model\n",
        "        up_state = up.state_dict()\n",
        "\n",
        "        to_load = {k: v for k, v in state_dict.items()\n",
        "                   if k in up_state and v.shape == up_state[k].shape}\n",
        "\n",
        "        missing, unexpected = up.load_state_dict(to_load, strict=False)\n",
        "\n",
        "        for k, v in to_load.items():\n",
        "            if not torch.equal(up_state[k], v):\n",
        "                raise RuntimeError(f\"Weight mismatch at '{k}' after loading checkpoint\")\n",
        "\n",
        "        print(f\"Successfully loaded {len(to_load)} parameters; missing: {len(missing)}, unexpected: {len(unexpected)}\")\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(cls, load_dir: str, map_location=None):\n",
        "        \"\"\"\n",
        "        Load a model checkpoint and hyperparameters from a directory.\n",
        "\n",
        "        Returns:\n",
        "            model (MammalClassifier): Loaded model\n",
        "        \"\"\"\n",
        "        hparams_path = os.path.join(load_dir, 'hparams.json')\n",
        "        with open(hparams_path, 'r') as f:\n",
        "            hparams = json.load(f)\n",
        "\n",
        "        model = cls(**hparams)\n",
        "        ckpt_path = os.path.join(load_dir, f'{cls.__name__}.ckpt')\n",
        "        state = torch.load(ckpt_path, map_location=map_location)\n",
        "        model.load_state_dict(state['state_dict'])\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sanity check\n",
        "model = WMMDClassifier(\n",
        "        num_classes=31, lr=1e-3,\n",
        "        backbone=\"mae-ast\", finetune=True,\n",
        "        class_weights=class_weights,\n",
        "        ckpt_path=\"4Enc_1Dec-61epoch-0.103loss.pt\"\n",
        "    )\n",
        "\n",
        "print(ModelSummary(model, max_depth=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ycDcNmcwQ_ON"
      },
      "outputs": [],
      "source": [
        "def WMMD_Collate(batch):\n",
        "    waveforms, labels = zip(*batch)\n",
        "    max_len = max(w.shape[0] for w in waveforms)\n",
        "    min_len = 5000\n",
        "    padded_len = max(max_len, min_len)\n",
        "\n",
        "    padded_waveforms = []\n",
        "    for waveform in waveforms:\n",
        "        padding_needed = padded_len - waveform.shape[0]\n",
        "        padded_waveform = torch.nn.functional.pad(waveform, (0, padding_needed))\n",
        "        padded_waveforms.append(padded_waveform)\n",
        "\n",
        "    padded = torch.stack(padded_waveforms, dim=0)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "    return padded, labels\n",
        "\n",
        "class WMMDSoundDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, backbone: str, target_sr: int = 2000):\n",
        "        \"\"\"\n",
        "        dataset: list of dicts with keys 'path' & 'label'\n",
        "        backbone: 'facebook/wav2vec2-base' or 'mae-ast'\n",
        "        target_sr: sampling rate (e.g. 2000)\n",
        "        \"\"\"\n",
        "        self.dataset = dataset\n",
        "        self.backbone = backbone.lower()\n",
        "        self.target_sr = target_sr\n",
        "        self.resampler_cache = {}\n",
        "\n",
        "        if self.backbone == \"facebook/wav2vec2-base\":\n",
        "            self.processor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
        "                \"facebook/wav2vec2-base\", return_attention_mask=False, sampling_rate=target_sr\n",
        "            )\n",
        "        elif self.backbone == \"mae-ast\":\n",
        "            self.processor = None\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported backbone '{backbone}'\")\n",
        "\n",
        "        labels = sorted({item['label'] for item in dataset})\n",
        "        self.label_to_int = {lbl: i for i, lbl in enumerate(labels)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        audio_path = item[\"path\"]\n",
        "        waveform, orig_sr = torchaudio.load(audio_path)\n",
        "\n",
        "        if orig_sr != self.target_sr:\n",
        "            if orig_sr not in self.resampler_cache:\n",
        "                self.resampler_cache[orig_sr] = torchaudio.transforms.Resample(orig_sr, self.target_sr)\n",
        "            waveform = self.resampler_cache[orig_sr](waveform)\n",
        "\n",
        "        waveform = waveform / (waveform.abs().max() + 1e-6)\n",
        "        wav_1d = waveform.squeeze(0)  \n",
        "        \n",
        "        if self.backbone == \"facebook/wav2vec2-base\":\n",
        "            arr = wav_1d.numpy()\n",
        "            feats = self.processor(arr, sampling_rate=self.target_sr, return_tensors=\"pt\")\n",
        "            inp = feats.input_values.squeeze(0)\n",
        "        elif self.backbone == \"mae-ast\":\n",
        "            inp = wav_1d\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported backbone '{self.backbone}'\")\n",
        "\n",
        "        lbl = self.label_to_int[item['label']]\n",
        "        return inp, lbl\n",
        "\n",
        "class WMMDDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset_dict,\n",
        "        backbone: str,\n",
        "        batch_size: int = 2,\n",
        "        num_workers: int = 1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dataset_dict = dataset_dict\n",
        "        self.backbone = backbone\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_ds = WMMDSoundDataset(self.dataset_dict[\"train\"], backbone=self.backbone)\n",
        "        self.val_ds   = WMMDSoundDataset(self.dataset_dict[\"validation\"], backbone=self.backbone)\n",
        "        self.test_ds  = WMMDSoundDataset(self.dataset_dict[\"test\"], backbone=self.backbone)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=True,\n",
        "            collate_fn=WMMD_Collate\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=True,\n",
        "            collate_fn=WMMD_Collate\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=True,\n",
        "            collate_fn=WMMD_Collate\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kQ2XWE-pRKAM"
      },
      "outputs": [],
      "source": [
        "# callback for logging metrics\n",
        "class MetricsLogger(pl.Callback):\n",
        "    def __init__(self):\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_accs = []\n",
        "        self.val_accs = []\n",
        "        self.train_precisions = []\n",
        "        self.val_precisions = []\n",
        "        self.train_recalls = []\n",
        "        self.val_recalls = []\n",
        "        self.train_f1s = []\n",
        "        self.val_f1s = []\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        m = trainer.callback_metrics\n",
        "        self.train_losses.append(m['train_loss'].item())\n",
        "        self.train_accs.append(m['train_acc'].item())\n",
        "        self.train_precisions.append(m['train_precision'].item())\n",
        "        self.train_recalls.append(m['train_recall'].item())\n",
        "        self.train_f1s.append(m['train_f1'].item())\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        m = trainer.callback_metrics\n",
        "        self.val_losses.append(m['val_loss'].item())\n",
        "        self.val_accs.append(m['val_acc'].item())\n",
        "        self.val_precisions.append(m['val_precision'].item())\n",
        "        self.val_recalls.append(m['val_recall'].item())\n",
        "        self.val_f1s.append(m['val_f1'].item())\n",
        "\n",
        "# callback for early stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    patience=10,\n",
        "    min_delta=0.01,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model configurations\n",
        "model_configs = [\n",
        "    # {\"num_classes\": num_classes, \"lr\": 1e-3, \"backbone\": \"facebook/wav2vec2-base\",  \"finetune\": False, \"class_weights\": class_weights, \"max_epochs\": 3, \"ckpt_path\": \"\"},\n",
        "    {\"num_classes\": num_classes, \"lr\": 1e-3, \"backbone\": \"mae-ast\",  \"finetune\": False, \"class_weights\": class_weights, \"max_epochs\": 3, \"ckpt_path\": \"4Enc_1Dec-61epoch-0.103loss.pt\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k7VBnf5TWfW"
      },
      "outputs": [],
      "source": [
        "# training Loops\n",
        "for cfg in model_configs:\n",
        "    dm = WMMDDataModule(\n",
        "        dataset_dict=ds,\n",
        "        backbone=cfg[\"backbone\"],\n",
        "        batch_size=2,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    model = WMMDClassifier(\n",
        "        num_classes=cfg['num_classes'], lr=cfg['lr'],\n",
        "        backbone=cfg['backbone'], finetune=cfg['finetune'],\n",
        "        class_weights=cfg['class_weights']\n",
        "    )\n",
        "    metrics_cb = MetricsLogger()\n",
        "    callbacks = [metrics_cb, early_stopping]\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=cfg['max_epochs'],\n",
        "        accelerator='gpu', devices=1,\n",
        "        precision='16-mixed', accumulate_grad_batches=2,\n",
        "        check_val_every_n_epoch=1,\n",
        "        num_sanity_val_steps=0,\n",
        "        enable_progress_bar=True, log_every_n_steps=1,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, dm)\n",
        "    test_res = trainer.test(model, dm)[0]\n",
        "\n",
        "    model.test_results = test_res\n",
        "    model.finish_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    model.epochs_trained = trainer.current_epoch + 1\n",
        "    model.save_model()\n",
        "\n",
        "    metrics_map = {\n",
        "        'accuracy':   ('train_accs',      'val_accs'),\n",
        "        'precision':  ('train_precisions','val_precisions'),\n",
        "        'recall':     ('train_recalls',   'val_recalls'),\n",
        "        'f1_score':   ('train_f1s',       'val_f1s'),\n",
        "    }\n",
        "    \n",
        "    for metric_name, (train_attr, val_attr) in metrics_map.items():\n",
        "        train_vals = getattr(metrics_cb, train_attr)\n",
        "        val_vals = getattr(metrics_cb, val_attr)\n",
        "        epochs = list(range(1, len(train_vals) + 1))\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(epochs, train_vals, label=f'train_{metric_name}')\n",
        "        plt.plot(epochs, val_vals,   label=f'val_{metric_name}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(metric_name.replace('_', ' ').title())\n",
        "        plt.title(f\"{metric_name.replace('_', ' ').title()} over Epochs {model._last_timestamp}\")\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc='best')\n",
        "\n",
        "        plot_file = os.path.join(model._last_save_dir, f\"{model._last_timestamp}_{metric_name}.png\")\n",
        "        plt.savefig(plot_file)\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"Completed {cfg['backbone']} ({'FT' if cfg['finetune'] else 'Frozen'}), artifacts in {model._last_save_dir}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "wmmd_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
