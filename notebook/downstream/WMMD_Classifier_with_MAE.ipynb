{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zqEAfZZYIaiX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/incantator/Documents/mbari-mae\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "# Numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2Model,\n",
    ")\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "\n",
    "# Metrics\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MAE-AST Library\n",
    "from s3prl.nn.upstream import S3PRLUpstream\n",
    "\n",
    "# Fix the length of the input audio to the same length\n",
    "def _match_length_force(self, xs, target_max_len):\n",
    "    xs_max_len = xs.size(1)\n",
    "    if xs_max_len > target_max_len:\n",
    "        xs = xs[:, :target_max_len, :]\n",
    "    elif xs_max_len < target_max_len:\n",
    "        pad_len = target_max_len - xs_max_len\n",
    "        xs = torch.cat(\n",
    "            (xs, xs[:, -1:, :].repeat(1, pad_len, 1)),\n",
    "            dim=1\n",
    "        )\n",
    "    return xs\n",
    "\n",
    "S3PRLUpstream._match_length = _match_length_force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "C5aQ8ZsGkD7s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1017 examples, 31 classes\n",
      "  Clymene_Dolphin: 38\n",
      "  Bottlenose_Dolphin: 15\n",
      "  Spinner_Dolphin: 69\n",
      "  Beluga,_White_Whale: 30\n",
      "  Bearded_Seal: 22\n",
      "  Minke_Whale: 10\n",
      "  Humpback_Whale: 38\n",
      "  Southern_Right_Whale: 15\n",
      "  White-sided_Dolphin: 33\n",
      "  Narwhal: 30\n",
      "  White-beaked_Dolphin: 34\n",
      "  Northern_Right_Whale: 32\n",
      "  Frasers_Dolphin: 52\n",
      "  Grampus,_Rissos_Dolphin: 40\n",
      "  Harp_Seal: 28\n",
      "  Atlantic_Spotted_Dolphin: 35\n",
      "  Fin,_Finback_Whale: 30\n",
      "  Ross_Seal: 30\n",
      "  Rough-Toothed_Dolphin: 30\n",
      "  Killer_Whale: 21\n",
      "  Pantropical_Spotted_Dolphin: 40\n",
      "  Short-Finned_Pacific_Pilot_Whale: 40\n",
      "  Bowhead_Whale: 36\n",
      "  False_Killer_Whale: 35\n",
      "  Melon_Headed_Whale: 38\n",
      "  Long-Finned_Pilot_Whale: 42\n",
      "  Striped_Dolphin: 49\n",
      "  Leopard_Seal: 6\n",
      "  Walrus: 23\n",
      "  Sperm_Whale: 45\n",
      "  Common_Dolphin: 31\n",
      "Validation dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 12\n",
      "  Bottlenose_Dolphin: 5\n",
      "  Spinner_Dolphin: 23\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 7\n",
      "  Minke_Whale: 4\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 11\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 18\n",
      "  Grampus,_Rissos_Dolphin: 13\n",
      "  Harp_Seal: 9\n",
      "  Atlantic_Spotted_Dolphin: 12\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 13\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 13\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 8\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 10\n",
      "Test dataset: 339 examples, 31 classes\n",
      "  Clymene_Dolphin: 13\n",
      "  Bottlenose_Dolphin: 4\n",
      "  Spinner_Dolphin: 22\n",
      "  Beluga,_White_Whale: 10\n",
      "  Bearded_Seal: 8\n",
      "  Minke_Whale: 3\n",
      "  Humpback_Whale: 13\n",
      "  Southern_Right_Whale: 5\n",
      "  White-sided_Dolphin: 11\n",
      "  Narwhal: 10\n",
      "  White-beaked_Dolphin: 12\n",
      "  Northern_Right_Whale: 11\n",
      "  Frasers_Dolphin: 17\n",
      "  Grampus,_Rissos_Dolphin: 14\n",
      "  Harp_Seal: 10\n",
      "  Atlantic_Spotted_Dolphin: 11\n",
      "  Fin,_Finback_Whale: 10\n",
      "  Ross_Seal: 10\n",
      "  Rough-Toothed_Dolphin: 10\n",
      "  Killer_Whale: 7\n",
      "  Pantropical_Spotted_Dolphin: 13\n",
      "  Short-Finned_Pacific_Pilot_Whale: 14\n",
      "  Bowhead_Whale: 12\n",
      "  False_Killer_Whale: 12\n",
      "  Melon_Headed_Whale: 12\n",
      "  Long-Finned_Pilot_Whale: 14\n",
      "  Striped_Dolphin: 16\n",
      "  Leopard_Seal: 2\n",
      "  Walrus: 7\n",
      "  Sperm_Whale: 15\n",
      "  Common_Dolphin: 11\n"
     ]
    }
   ],
   "source": [
    "# loading the dataset\n",
    "data_dir = \"data/watkins\"\n",
    "annotations_file_train = os.path.join(data_dir, \"annotations.train.csv\")\n",
    "annotations_file_valid = os.path.join(data_dir, \"annotations.valid.csv\")\n",
    "annotations_file_test = os.path.join(data_dir, \"annotations.test.csv\")\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\"train\": annotations_file_train,\n",
    "                \"validation\": annotations_file_valid,\n",
    "                \"test\": annotations_file_test},\n",
    ")\n",
    "\n",
    "for split_name in [\"train\", \"validation\", \"test\"]:\n",
    "    split_dataset = ds[split_name]\n",
    "    labels = split_dataset[\"label\"]\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "\n",
    "    print(f\"{split_name.capitalize()} dataset: {total} examples, {len(counts)} classes\")\n",
    "    if \"label\" in split_dataset.features and hasattr(split_dataset.features[\"label\"], \"names\"):\n",
    "        class_names = split_dataset.features[\"label\"].names\n",
    "        for idx, name in enumerate(class_names):\n",
    "            print(f\"  {idx} ({name}): {counts.get(name, 0)}\")\n",
    "    else:\n",
    "        for label, count in counts.items():\n",
    "            print(f\"  {label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weights calculation\n",
    "train_labels = ds[\"train\"][\"label\"]\n",
    "unique_labels = sorted(set(train_labels))\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "y_train = [label_to_int[lbl] for lbl in train_labels]\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(unique_labels)),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "num_classes = len(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6JYR66KeIUsg"
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "class WMMDClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        lr: float = 1e-3,\n",
    "        backbone: str = \"facebook/wav2vec2-base\",\n",
    "        ckpt_path: str = \"\",\n",
    "        finetune: bool = False,\n",
    "        class_weights=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        if backbone == \"facebook/wav2vec2-base\":\n",
    "            self.backbone     = Wav2Vec2Model.from_pretrained(backbone)\n",
    "            self.embedding_dim = self.backbone.config.hidden_size\n",
    "        \n",
    "        elif backbone == \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\":\n",
    "            self.backbone     = Wav2Vec2Model.from_pretrained(backbone)\n",
    "            self.embedding_dim = self.backbone.config.hidden_size\n",
    "        \n",
    "        elif backbone.lower() == \"mae-ast\":\n",
    "            up_kwargs = {\"name\": \"mae_ast_patch\"}\n",
    "            s3 = S3PRLUpstream(**up_kwargs)\n",
    "\n",
    "            enc = s3.upstream.model.encoder\n",
    "            enc.layers = nn.ModuleList(list(enc.layers)[:4])\n",
    "            s3.upstream.model.dec_sine_pos_embed = None\n",
    "            s3.upstream.model.decoder = None\n",
    "            s3.upstream.model.final_proj_reconstruction = None\n",
    "            s3.upstream.model.final_proj_classification  = None\n",
    "\n",
    "            new_n = len(enc.layers)\n",
    "            s3._num_layers       = new_n\n",
    "            s3._hidden_sizes     = s3._hidden_sizes[:new_n]\n",
    "            s3._downsample_rates = s3._downsample_rates[:new_n]\n",
    "\n",
    "            self.backbone      = s3\n",
    "            self.embedding_dim = s3.hidden_sizes[-1]\n",
    "\n",
    "            # Load the checkpoint for mae ast\n",
    "            if ckpt_path:\n",
    "                self.load_mae_ckpt(ckpt_path)\n",
    "            \n",
    "            mel_transform = T.MelSpectrogram(\n",
    "                sample_rate=2000, n_fft=1024, win_length=512,\n",
    "                hop_length=20, n_mels=128,\n",
    "            )\n",
    "\n",
    "            class DBWithDeltas(nn.Module):\n",
    "                def __init__(self):\n",
    "                    super().__init__()\n",
    "\n",
    "                def forward(self, spec):\n",
    "                    spec_db = F.amplitude_to_DB(\n",
    "                        spec,\n",
    "                        multiplier=10.0,\n",
    "                        amin=1e-10,\n",
    "                        db_multiplier=0\n",
    "                    )\n",
    "                    t = spec_db.transpose(0, 1)\n",
    "                    d1 = F.compute_deltas(t.transpose(0,1))\n",
    "                    d2 = F.compute_deltas(d1)\n",
    "                    return torch.cat([\n",
    "                        t,\n",
    "                        d1.transpose(0,1),\n",
    "                        d2.transpose(0,1)\n",
    "                    ], dim=1)\n",
    "            \n",
    "            s3.upstream.model.fbank   = mel_transform\n",
    "            s3.upstream.model.db_norm = DBWithDeltas()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone '{backbone}'\")\n",
    "\n",
    "        try:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = finetune\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.embedding_dim, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "        if class_weights is not None:\n",
    "            cw = torch.tensor(class_weights, dtype=torch.float)\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=cw)\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        metrics_kwargs = dict(num_classes=num_classes, average='macro')\n",
    "        self.train_precision = MulticlassPrecision(**metrics_kwargs)\n",
    "        self.train_recall = MulticlassRecall(**metrics_kwargs)\n",
    "        self.train_f1 = MulticlassF1Score(**metrics_kwargs)\n",
    "        self.val_precision = MulticlassPrecision(**metrics_kwargs)\n",
    "        self.val_recall = MulticlassRecall(**metrics_kwargs)\n",
    "        self.val_f1 = MulticlassF1Score(**metrics_kwargs)\n",
    "        self.test_precision = MulticlassPrecision(**metrics_kwargs)\n",
    "        self.test_recall = MulticlassRecall(**metrics_kwargs)\n",
    "        self.test_f1 = MulticlassF1Score(**metrics_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bname = self.hparams.backbone.lower()\n",
    "        if bname == \"facebook/wav2vec2-base\":\n",
    "            out = self.backbone(x)\n",
    "            hidden = out.last_hidden_state\n",
    "        elif bname == \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\":\n",
    "            out = self.backbone(x)\n",
    "            hidden = out.last_hidden_state\n",
    "        elif bname == \"mae-ast\":\n",
    "            if x.dim() == 3:\n",
    "                x = x.squeeze(-1)\n",
    "            wav_lens = torch.full((x.size(0),), x.size(1),\n",
    "                                dtype=torch.long, device=x.device)\n",
    "            all_hs, _ = self.backbone(x, wav_lens)\n",
    "            hidden   = all_hs[-1]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone in forward(): '{self.hparams.backbone}'\")\n",
    "\n",
    "        emb = hidden.mean(dim=1)\n",
    "        return self.classifier(emb)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        self.log_batch_metrics(loss, preds, y, prefix='train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        self.log_batch_metrics(loss, preds, y, prefix='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        self.log_batch_metrics(loss, preds, y, prefix='test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "    def log_batch_metrics(self, loss, preds, targets, prefix):\n",
    "        self.log(f'{prefix}_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        acc = (preds == targets).float().mean()\n",
    "        self.log(f'{prefix}_acc', acc, prog_bar=True, on_epoch=True)\n",
    "        precision = getattr(self, f'{prefix}_precision')(preds, targets)\n",
    "        recall = getattr(self, f'{prefix}_recall')(preds, targets)\n",
    "        f1 = getattr(self, f'{prefix}_f1')(preds, targets)\n",
    "        self.log(f'{prefix}_precision', precision, on_epoch=True)\n",
    "        self.log(f'{prefix}_recall', recall, on_epoch=True)\n",
    "        self.log(f'{prefix}_f1', f1, on_epoch=True)\n",
    "\n",
    "    def on_train_end(self):\n",
    "        save_dir = getattr(self, 'save_dir', None)\n",
    "        if save_dir:\n",
    "            self.save_model(save_dir)\n",
    "\n",
    "    def save_model(self):\n",
    "        base_dir = 'model'\n",
    "        bn = self.hparams.backbone.replace('/', '_')\n",
    "        cw = getattr(self.hparams, 'class_weights', None)\n",
    "        balance_flag = 'imbalance' if cw is not None else 'balance'\n",
    "        timestamp = getattr(self, 'finish_time', datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "        folder = os.path.join(base_dir, f\"{bn}_{balance_flag}\", timestamp)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        ckpt_path = os.path.join(folder, f\"{timestamp}.pt\")\n",
    "        payload = {\n",
    "            'state_dict': self.state_dict(),\n",
    "            'hparams': dict(self.hparams)\n",
    "        }\n",
    "        for attr in ('test_results', 'finish_time', 'epochs_trained'):\n",
    "            if hasattr(self, attr):\n",
    "                payload[attr] = getattr(self, attr)\n",
    "        torch.save(payload, ckpt_path)\n",
    "\n",
    "        stats_path = os.path.join(folder, f\"{timestamp}.txt\")\n",
    "        raw_hparams = dict(self.hparams)\n",
    "        serializable_hparams = {}\n",
    "        for k, v in raw_hparams.items():\n",
    "            if isinstance(v, np.ndarray):\n",
    "                serializable_hparams[k] = v.tolist()\n",
    "            elif isinstance(v, torch.Tensor):\n",
    "                serializable_hparams[k] = v.cpu().item() if v.ndim == 0 else v.cpu().tolist()\n",
    "            else:\n",
    "                serializable_hparams[k] = v\n",
    "\n",
    "        serializable_results = {}\n",
    "        if hasattr(self, 'test_results'):\n",
    "            for k, v in self.test_results.items():\n",
    "                serializable_results[k] = v.cpu().item() if isinstance(v, torch.Tensor) else v\n",
    "\n",
    "        with open(stats_path, 'w') as f:\n",
    "            f.write(f\"Model architecture:\\n{self}\\n\\n\")\n",
    "            f.write(\"Hyperparameters:\\n\")\n",
    "            f.write(json.dumps(serializable_hparams, indent=4))\n",
    "            f.write(\"\\n\\n\")\n",
    "            if serializable_results:\n",
    "                f.write(\"Test results:\\n\")\n",
    "                f.write(json.dumps(serializable_results, indent=4))\n",
    "                f.write(\"\\n\\n\")\n",
    "            if hasattr(self, 'epochs_trained'):\n",
    "                f.write(f\"Epochs trained: {self.epochs_trained}\\n\")\n",
    "\n",
    "        self._last_save_dir = folder\n",
    "        self._last_timestamp = timestamp\n",
    "        print(f\"Artifacts saved to {folder}/\")\n",
    "    \n",
    "    def load_mae_ckpt(self, ckpt_source: str):\n",
    "        \"\"\"\n",
    "        Load MAE-AST checkpoint into the truncated upstream model\n",
    "        and verify exact weight equality for each loaded parameter.\n",
    "        \"\"\"\n",
    "        loaded = torch.load(ckpt_source)\n",
    "        state_dict = loaded.get('model', loaded)\n",
    "\n",
    "        up = self.backbone.upstream.model\n",
    "        up_state = up.state_dict()\n",
    "\n",
    "        to_load = {k: v for k, v in state_dict.items()\n",
    "                   if k in up_state and v.shape == up_state[k].shape}\n",
    "\n",
    "        missing, unexpected = up.load_state_dict(to_load, strict=False)\n",
    "\n",
    "        for k, v in to_load.items():\n",
    "            if not torch.equal(up_state[k], v):\n",
    "                raise RuntimeError(f\"Weight mismatch at '{k}' after loading checkpoint\")\n",
    "\n",
    "        print(f\"Successfully loaded {len(to_load)} parameters; missing: {len(missing)}, unexpected: {len(unexpected)}\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, load_dir: str, map_location=None):\n",
    "        \"\"\"\n",
    "        Load a model checkpoint and hyperparameters from a directory.\n",
    "\n",
    "        Returns:\n",
    "            model (MammalClassifier): Loaded model\n",
    "        \"\"\"\n",
    "        hparams_path = os.path.join(load_dir, 'hparams.json')\n",
    "        with open(hparams_path, 'r') as f:\n",
    "            hparams = json.load(f)\n",
    "\n",
    "        model = cls(**hparams)\n",
    "        ckpt_path = os.path.join(load_dir, f'{cls.__name__}.ckpt')\n",
    "        state = torch.load(ckpt_path, map_location=map_location)\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2879197b995749f99de6e3fc0b6f4856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeeaa80f1b4d4581a307341f7f19a1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/829k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d7ce440c1749929bd909e0d6cdfc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/812k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# sanity check\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWMMDClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpatrickvonplaten/tiny-wav2vec2-no-tokenizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinetune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(ModelSummary(model, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mWMMDClassifier.__init__\u001b[0;34m(self, num_classes, lr, backbone, ckpt_path, finetune, class_weights)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backbone \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatrickvonplaten/tiny-wav2vec2-no-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone     \u001b[38;5;241m=\u001b[39m \u001b[43mWav2Vec2Model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backbone\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae-ast\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/mbari-mae/venv/lib/python3.9/site-packages/transformers/modeling_utils.py:311\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/Documents/mbari-mae/venv/lib/python3.9/site-packages/transformers/modeling_utils.py:4833\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4824\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4826\u001b[0m     (\n\u001b[1;32m   4827\u001b[0m         model,\n\u001b[1;32m   4828\u001b[0m         missing_keys,\n\u001b[1;32m   4829\u001b[0m         unexpected_keys,\n\u001b[1;32m   4830\u001b[0m         mismatched_keys,\n\u001b[1;32m   4831\u001b[0m         offload_index,\n\u001b[1;32m   4832\u001b[0m         error_msgs,\n\u001b[0;32m-> 4833\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4839\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4842\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4851\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[1;32m   4852\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[0;32m~/Documents/mbari-mae/venv/lib/python3.9/site-packages/transformers/modeling_utils.py:5099\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5096\u001b[0m     original_checkpoint_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(state_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   5097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5098\u001b[0m     original_checkpoint_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m-> 5099\u001b[0m         \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m   5100\u001b[0m     )\n\u001b[1;32m   5102\u001b[0m \u001b[38;5;66;03m# Check if we are in a special state, i.e. loading from a state dict coming from a different architecture\u001b[39;00m\n\u001b[1;32m   5103\u001b[0m prefix \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbase_model_prefix\n",
      "File \u001b[0;32m~/Documents/mbari-mae/venv/lib/python3.9/site-packages/transformers/modeling_utils.py:556\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# Fallback to torch.load (if weights_only was explicitly False, do not check safety as this is known to be unsafe)\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m--> 556\u001b[0m     \u001b[43mcheck_torch_load_is_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m map_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/mbari-mae/venv/lib/python3.9/site-packages/transformers/utils/import_utils.py:1517\u001b[0m, in \u001b[0;36mcheck_torch_load_is_safe\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_torch_load_is_safe\u001b[39m():\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.6\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1518\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDue to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1519\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1520\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen loading files with safetensors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1521\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1522\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 640M/662M [21:53<00:44, 518kB/s]"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "model = WMMDClassifier(\n",
    "        num_classes=31, lr=1e-3,\n",
    "        backbone=\"patrickvonplaten/tiny-wav2vec2-no-tokenizer\", finetune=True,\n",
    "        class_weights=class_weights,\n",
    "        ckpt_path=\"\"\n",
    "    )\n",
    "\n",
    "print(ModelSummary(model, max_depth=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: https://www.cs.utexas.edu/~harwath/model_checkpoints/mae_ast/chunk_patch_75_12LayerEncoder.pt\n",
      "Destination: /home/incantator/.cache/s3prl/download/5e5fe701120580b1447c34e87c2f1bf9ac58e3ae2df707ea5e2fd85eeab0e0a9.chunk_patch_75_12LayerEncoder.pt\n",
      "  4%|█████▎                                                                                                                                              | 23.8M/662M [00:45<20:31, 543kB/s]\n",
      "urllib.Request method failed. Trying using another method...\n",
      "Downloading: https://www.cs.utexas.edu/~harwath/model_checkpoints/mae_ast/chunk_patch_75_12LayerEncoder.pt\n",
      "Destination: /home/incantator/.cache/s3prl/download/5e5fe701120580b1447c34e87c2f1bf9ac58e3ae2df707ea5e2fd85eeab0e0a9.chunk_patch_75_12LayerEncoder.pt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 662M/662M [22:28<00:00, 515kB/s]\n",
      "/home/incantator/Documents/mbari-mae/venv/lib/python3.9/site-packages/s3prl/upstream/mae_ast/expert.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt, map_location=\"cpu\")\n",
      "/tmp/ipykernel_63455/630877468.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded = torch.load(ckpt_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 76 parameters; missing: 0, unexpected: 0\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | S3PRLUpstream       | 28.6 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "34.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.9 M    Total params\n",
      "139.506   Total estimated model params size (MB)\n",
      "89        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "model = WMMDClassifier(\n",
    "        num_classes=31, lr=1e-3,\n",
    "        backbone=\"mae-ast\", finetune=True,\n",
    "        class_weights=class_weights,\n",
    "        ckpt_path=\"4Enc_1Dec-61epoch-0.103loss.pt\"\n",
    "    )\n",
    "\n",
    "print(ModelSummary(model, max_depth=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ycDcNmcwQ_ON"
   },
   "outputs": [],
   "source": [
    "def WMMD_Collate(batch):\n",
    "    waveforms, labels = zip(*batch)\n",
    "\n",
    "    lengths    = [w.shape[0] for w in waveforms]\n",
    "    raw_max    = max(lengths)\n",
    "\n",
    "    min_len    = 5_000\n",
    "    max_len    = 25_000\n",
    "    target_len = min(max(raw_max, min_len), max_len)\n",
    "\n",
    "    padded_waveforms = []\n",
    "    for w in waveforms:\n",
    "        L = w.shape[0]\n",
    "\n",
    "        if L > target_len:\n",
    "            start = random.randint(0, L - target_len)\n",
    "            w2    = w[start : start + target_len]\n",
    "\n",
    "        elif L < target_len:\n",
    "            pad_amt = target_len - L\n",
    "            w2      = torch.nn.functional.pad(w, (0, pad_amt))\n",
    "\n",
    "        else:\n",
    "            w2 = w\n",
    "\n",
    "        padded_waveforms.append(w2)\n",
    "\n",
    "    batch_waveforms = torch.stack(padded_waveforms, dim=0)\n",
    "    batch_labels    = torch.tensor(labels, dtype=torch.long)\n",
    "    return batch_waveforms, batch_labels\n",
    "\n",
    "class WMMDSoundDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, backbone: str, target_sr: int = 2000):\n",
    "        \"\"\"\n",
    "        dataset: list of dicts with keys 'path' & 'label'\n",
    "        backbone: 'facebook/wav2vec2-base' or 'mae-ast'\n",
    "        target_sr: sampling rate (e.g. 2000)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.backbone = backbone.lower()\n",
    "        self.target_sr = target_sr\n",
    "        self.resampler_cache = {}\n",
    "\n",
    "        if self.backbone == \"facebook/wav2vec2-base\":\n",
    "            self.processor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "                \"facebook/wav2vec2-base\", return_attention_mask=False, sampling_rate=target_sr\n",
    "            )\n",
    "        elif self.backbone == \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\":\n",
    "            self.processor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "                \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\", return_attention_mask=False, sampling_rate=target_sr\n",
    "            )\n",
    "        elif self.backbone == \"mae-ast\":\n",
    "            self.processor = None\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone '{backbone}'\")\n",
    "\n",
    "        labels = sorted({item['label'] for item in dataset})\n",
    "        self.label_to_int = {lbl: i for i, lbl in enumerate(labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        audio_path = item[\"path\"]\n",
    "        waveform, orig_sr = torchaudio.load(audio_path)\n",
    "\n",
    "        if orig_sr != self.target_sr:\n",
    "            if orig_sr not in self.resampler_cache:\n",
    "                self.resampler_cache[orig_sr] = torchaudio.transforms.Resample(orig_sr, self.target_sr)\n",
    "            waveform = self.resampler_cache[orig_sr](waveform)\n",
    "\n",
    "        waveform = waveform / (waveform.abs().max() + 1e-6)\n",
    "        wav_1d = waveform.squeeze(0)  \n",
    "        \n",
    "        if self.backbone == \"facebook/wav2vec2-base\":\n",
    "            arr = wav_1d.numpy()\n",
    "            feats = self.processor(arr, sampling_rate=self.target_sr, return_tensors=\"pt\")\n",
    "            inp = feats.input_values.squeeze(0)\n",
    "        elif self.backbone == \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\":\n",
    "            arr = wav_1d.numpy()\n",
    "            feats = self.processor(arr, sampling_rate=self.target_sr, return_tensors=\"pt\")\n",
    "            inp = feats.input_values.squeeze(0)\n",
    "        elif self.backbone == \"mae-ast\":\n",
    "            inp = wav_1d\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone '{self.backbone}'\")\n",
    "\n",
    "        lbl = self.label_to_int[item['label']]\n",
    "        return inp, lbl\n",
    "\n",
    "class WMMDDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_dict,\n",
    "        backbone: str,\n",
    "        batch_size: int = 2,\n",
    "        num_workers: int = 1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dataset_dict = dataset_dict\n",
    "        self.backbone = backbone\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_ds = WMMDSoundDataset(self.dataset_dict[\"train\"], backbone=self.backbone)\n",
    "        self.val_ds   = WMMDSoundDataset(self.dataset_dict[\"validation\"], backbone=self.backbone)\n",
    "        self.test_ds  = WMMDSoundDataset(self.dataset_dict[\"test\"], backbone=self.backbone)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=WMMD_Collate\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=WMMD_Collate\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            collate_fn=WMMD_Collate\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kQ2XWE-pRKAM"
   },
   "outputs": [],
   "source": [
    "# callback for logging metrics\n",
    "class MetricsLogger(pl.Callback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "        self.train_precisions = []\n",
    "        self.val_precisions = []\n",
    "        self.train_recalls = []\n",
    "        self.val_recalls = []\n",
    "        self.train_f1s = []\n",
    "        self.val_f1s = []\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        m = trainer.callback_metrics\n",
    "        self.train_losses.append(m['train_loss'].item())\n",
    "        self.train_accs.append(m['train_acc'].item())\n",
    "        self.train_precisions.append(m['train_precision'].item())\n",
    "        self.train_recalls.append(m['train_recall'].item())\n",
    "        self.train_f1s.append(m['train_f1'].item())\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        m = trainer.callback_metrics\n",
    "        self.val_losses.append(m['val_loss'].item())\n",
    "        self.val_accs.append(m['val_acc'].item())\n",
    "        self.val_precisions.append(m['val_precision'].item())\n",
    "        self.val_recalls.append(m['val_recall'].item())\n",
    "        self.val_f1s.append(m['val_f1'].item())\n",
    "\n",
    "# callback for early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    min_delta=0.01,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configurations\n",
    "model_configs = [\n",
    "    # {\"num_classes\": num_classes, \"lr\": 1e-3, \"backbone\": \"facebook/wav2vec2-base\",  \"finetune\": False, \"class_weights\": class_weights, \"max_epochs\": 500, \"ckpt_path\": \"\"},\n",
    "    {\"num_classes\": num_classes, \"lr\": 1e-6, \"backbone\": \"mae-ast\",  \"finetune\": True, \"class_weights\": class_weights, \"max_epochs\": 500, \"ckpt_path\": \"4Enc_1Dec-61epoch-0.103loss.pt\"},\n",
    "    # {\"num_classes\": num_classes, \"lr\": 1e-3, \"backbone\": \"patrickvonplaten/tiny-wav2vec2-no-tokenizer\",  \"finetune\": True, \"class_weights\": class_weights, \"max_epochs\": 500, \"ckpt_path\": \"\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9k7VBnf5TWfW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX 2000 Ada Generation Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 76 parameters; missing: 0, unexpected: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | backbone        | S3PRLUpstream       | 28.6 M | train\n",
      "1  | classifier      | Sequential          | 6.3 M  | train\n",
      "2  | criterion       | CrossEntropyLoss    | 0      | train\n",
      "3  | train_precision | MulticlassPrecision | 0      | train\n",
      "4  | train_recall    | MulticlassRecall    | 0      | train\n",
      "5  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "6  | val_precision   | MulticlassPrecision | 0      | train\n",
      "7  | val_recall      | MulticlassRecall    | 0      | train\n",
      "8  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "9  | test_precision  | MulticlassPrecision | 0      | train\n",
      "10 | test_recall     | MulticlassRecall    | 0      | train\n",
      "11 | test_f1         | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "34.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.9 M    Total params\n",
      "139.506   Total estimated model params size (MB)\n",
      "89        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\yohanes.setiawan\\AppData\\Local\\miniconda3\\envs\\wmmd_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\yohanes.setiawan\\AppData\\Local\\miniconda3\\envs\\wmmd_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 509/509 [00:30<00:00, 16.43it/s, v_num=33, train_loss_step=3.290, train_acc_step=0.000, val_loss=3.340, val_acc=0.0826, train_loss_epoch=3.450, train_acc_epoch=0.0433]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 3.339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 509/509 [00:29<00:00, 17.05it/s, v_num=33, train_loss_step=2.670, train_acc_step=1.000, val_loss=3.270, val_acc=0.142, train_loss_epoch=3.390, train_acc_epoch=0.0659] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.070 >= min_delta = 0.01. New best score: 3.269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 509/509 [00:36<00:00, 14.04it/s, v_num=33, train_loss_step=2.690, train_acc_step=0.000, val_loss=3.210, val_acc=0.159, train_loss_epoch=3.310, train_acc_epoch=0.106] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.064 >= min_delta = 0.01. New best score: 3.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 509/509 [00:47<00:00, 10.71it/s, v_num=33, train_loss_step=3.540, train_acc_step=0.000, val_loss=3.160, val_acc=0.183, train_loss_epoch=3.280, train_acc_epoch=0.134]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.049 >= min_delta = 0.01. New best score: 3.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 509/509 [00:30<00:00, 16.78it/s, v_num=33, train_loss_step=3.070, train_acc_step=0.000, val_loss=3.110, val_acc=0.189, train_loss_epoch=3.230, train_acc_epoch=0.135]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.048 >= min_delta = 0.01. New best score: 3.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 509/509 [00:41<00:00, 12.34it/s, v_num=33, train_loss_step=1.560, train_acc_step=1.000, val_loss=3.070, val_acc=0.195, train_loss_epoch=3.190, train_acc_epoch=0.163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.043 >= min_delta = 0.01. New best score: 3.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 509/509 [00:50<00:00, 10.16it/s, v_num=33, train_loss_step=2.770, train_acc_step=0.000, val_loss=3.020, val_acc=0.195, train_loss_epoch=3.140, train_acc_epoch=0.166]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.042 >= min_delta = 0.01. New best score: 3.023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 509/509 [00:51<00:00,  9.81it/s, v_num=33, train_loss_step=3.510, train_acc_step=0.000, val_loss=2.980, val_acc=0.201, train_loss_epoch=3.100, train_acc_epoch=0.166]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.043 >= min_delta = 0.01. New best score: 2.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 509/509 [00:51<00:00,  9.89it/s, v_num=33, train_loss_step=2.960, train_acc_step=0.000, val_loss=2.940, val_acc=0.206, train_loss_epoch=3.080, train_acc_epoch=0.185]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.041 >= min_delta = 0.01. New best score: 2.940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 509/509 [00:50<00:00, 10.15it/s, v_num=33, train_loss_step=3.230, train_acc_step=0.000, val_loss=2.910, val_acc=0.245, train_loss_epoch=3.040, train_acc_epoch=0.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.035 >= min_delta = 0.01. New best score: 2.905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 509/509 [00:36<00:00, 13.97it/s, v_num=33, train_loss_step=2.270, train_acc_step=1.000, val_loss=2.860, val_acc=0.257, train_loss_epoch=3.010, train_acc_epoch=0.180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.044 >= min_delta = 0.01. New best score: 2.861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 509/509 [00:47<00:00, 10.63it/s, v_num=33, train_loss_step=3.370, train_acc_step=0.000, val_loss=2.830, val_acc=0.242, train_loss_epoch=2.970, train_acc_epoch=0.206]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.01. New best score: 2.833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 509/509 [00:47<00:00, 10.76it/s, v_num=33, train_loss_step=3.410, train_acc_step=0.000, val_loss=2.800, val_acc=0.257, train_loss_epoch=2.950, train_acc_epoch=0.215]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.037 >= min_delta = 0.01. New best score: 2.796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 509/509 [00:46<00:00, 11.02it/s, v_num=33, train_loss_step=2.600, train_acc_step=0.000, val_loss=2.770, val_acc=0.257, train_loss_epoch=2.920, train_acc_epoch=0.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.01. New best score: 2.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 509/509 [00:36<00:00, 13.93it/s, v_num=33, train_loss_step=2.330, train_acc_step=1.000, val_loss=2.740, val_acc=0.257, train_loss_epoch=2.880, train_acc_epoch=0.229]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.01. New best score: 2.742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 509/509 [00:29<00:00, 17.31it/s, v_num=33, train_loss_step=3.950, train_acc_step=0.000, val_loss=2.710, val_acc=0.263, train_loss_epoch=2.850, train_acc_epoch=0.232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.030 >= min_delta = 0.01. New best score: 2.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 509/509 [00:28<00:00, 17.85it/s, v_num=33, train_loss_step=2.350, train_acc_step=1.000, val_loss=2.690, val_acc=0.263, train_loss_epoch=2.820, train_acc_epoch=0.221]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.01. New best score: 2.690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 509/509 [00:28<00:00, 17.58it/s, v_num=33, train_loss_step=2.210, train_acc_step=1.000, val_loss=2.670, val_acc=0.265, train_loss_epoch=2.790, train_acc_epoch=0.248]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.01. New best score: 2.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 509/509 [00:29<00:00, 17.28it/s, v_num=33, train_loss_step=0.301, train_acc_step=1.000, val_loss=2.650, val_acc=0.257, train_loss_epoch=2.770, train_acc_epoch=0.257]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.01. New best score: 2.649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 509/509 [00:28<00:00, 17.65it/s, v_num=33, train_loss_step=3.380, train_acc_step=0.000, val_loss=2.620, val_acc=0.289, train_loss_epoch=2.740, train_acc_epoch=0.252]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.01. New best score: 2.617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 509/509 [00:39<00:00, 12.91it/s, v_num=33, train_loss_step=2.110, train_acc_step=0.000, val_loss=2.590, val_acc=0.292, train_loss_epoch=2.710, train_acc_epoch=0.279]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.01. New best score: 2.593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 509/509 [00:53<00:00,  9.52it/s, v_num=33, train_loss_step=3.240, train_acc_step=0.000, val_loss=2.580, val_acc=0.301, train_loss_epoch=2.710, train_acc_epoch=0.264] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.01. New best score: 2.578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 509/509 [00:29<00:00, 17.43it/s, v_num=33, train_loss_step=3.100, train_acc_step=0.000, val_loss=2.550, val_acc=0.316, train_loss_epoch=2.680, train_acc_epoch=0.275]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.01. New best score: 2.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 509/509 [00:28<00:00, 17.57it/s, v_num=33, train_loss_step=3.500, train_acc_step=0.000, val_loss=2.530, val_acc=0.316, train_loss_epoch=2.650, train_acc_epoch=0.286]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.01. New best score: 2.529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 509/509 [00:56<00:00,  9.07it/s, v_num=33, train_loss_step=3.210, train_acc_step=0.000, val_loss=2.510, val_acc=0.304, train_loss_epoch=2.630, train_acc_epoch=0.286]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.01. New best score: 2.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 509/509 [01:08<00:00,  7.48it/s, v_num=33, train_loss_step=2.490, train_acc_step=1.000, val_loss=2.490, val_acc=0.319, train_loss_epoch=2.620, train_acc_epoch=0.274]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.025 >= min_delta = 0.01. New best score: 2.488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 509/509 [00:59<00:00,  8.51it/s, v_num=33, train_loss_step=2.320, train_acc_step=0.000, val_loss=2.450, val_acc=0.330, train_loss_epoch=2.580, train_acc_epoch=0.300]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.034 >= min_delta = 0.01. New best score: 2.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 509/509 [00:59<00:00,  8.53it/s, v_num=33, train_loss_step=2.750, train_acc_step=0.000, val_loss=2.440, val_acc=0.324, train_loss_epoch=2.560, train_acc_epoch=0.305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.01. New best score: 2.441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 509/509 [00:54<00:00,  9.30it/s, v_num=33, train_loss_step=2.590, train_acc_step=0.000, val_loss=2.410, val_acc=0.357, train_loss_epoch=2.530, train_acc_epoch=0.331] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.026 >= min_delta = 0.01. New best score: 2.415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 509/509 [00:48<00:00, 10.39it/s, v_num=33, train_loss_step=1.200, train_acc_step=1.000, val_loss=2.370, val_acc=0.345, train_loss_epoch=2.500, train_acc_epoch=0.320]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.048 >= min_delta = 0.01. New best score: 2.367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 509/509 [00:47<00:00, 10.62it/s, v_num=33, train_loss_step=2.850, train_acc_step=0.000, val_loss=2.350, val_acc=0.357, train_loss_epoch=2.480, train_acc_epoch=0.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.01. New best score: 2.345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 509/509 [00:49<00:00, 10.33it/s, v_num=33, train_loss_step=1.210, train_acc_step=1.000, val_loss=2.320, val_acc=0.369, train_loss_epoch=2.420, train_acc_epoch=0.343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.01. New best score: 2.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 509/509 [00:49<00:00, 10.32it/s, v_num=33, train_loss_step=3.420, train_acc_step=0.000, val_loss=2.300, val_acc=0.366, train_loss_epoch=2.420, train_acc_epoch=0.330]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.01. New best score: 2.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 509/509 [00:47<00:00, 10.63it/s, v_num=33, train_loss_step=0.137, train_acc_step=1.000, val_loss=2.280, val_acc=0.381, train_loss_epoch=2.380, train_acc_epoch=0.366]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.027 >= min_delta = 0.01. New best score: 2.277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 509/509 [00:35<00:00, 14.53it/s, v_num=33, train_loss_step=3.760, train_acc_step=0.000, val_loss=2.260, val_acc=0.375, train_loss_epoch=2.340, train_acc_epoch=0.369]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.01. New best score: 2.258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 509/509 [00:30<00:00, 16.66it/s, v_num=33, train_loss_step=2.520, train_acc_step=0.000, val_loss=2.230, val_acc=0.383, train_loss_epoch=2.350, train_acc_epoch=0.367] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.01. New best score: 2.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 509/509 [00:29<00:00, 17.10it/s, v_num=33, train_loss_step=2.780, train_acc_step=0.000, val_loss=2.210, val_acc=0.375, train_loss_epoch=2.300, train_acc_epoch=0.378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.01. New best score: 2.214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 509/509 [00:31<00:00, 16.34it/s, v_num=33, train_loss_step=2.730, train_acc_step=0.000, val_loss=2.200, val_acc=0.378, train_loss_epoch=2.310, train_acc_epoch=0.373]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.01. New best score: 2.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 509/509 [00:31<00:00, 16.40it/s, v_num=33, train_loss_step=0.0928, train_acc_step=1.000, val_loss=2.170, val_acc=0.378, train_loss_epoch=2.250, train_acc_epoch=0.380]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.027 >= min_delta = 0.01. New best score: 2.170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 509/509 [00:32<00:00, 15.54it/s, v_num=33, train_loss_step=3.060, train_acc_step=0.000, val_loss=2.140, val_acc=0.392, train_loss_epoch=2.210, train_acc_epoch=0.393] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.027 >= min_delta = 0.01. New best score: 2.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 509/509 [00:29<00:00, 17.35it/s, v_num=33, train_loss_step=1.520, train_acc_step=1.000, val_loss=2.120, val_acc=0.410, train_loss_epoch=2.210, train_acc_epoch=0.398] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.01. New best score: 2.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 509/509 [00:29<00:00, 17.40it/s, v_num=33, train_loss_step=2.020, train_acc_step=1.000, val_loss=2.100, val_acc=0.419, train_loss_epoch=2.180, train_acc_epoch=0.408]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.01. New best score: 2.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 509/509 [00:30<00:00, 16.92it/s, v_num=33, train_loss_step=1.870, train_acc_step=0.000, val_loss=2.090, val_acc=0.419, train_loss_epoch=2.150, train_acc_epoch=0.418]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.01. New best score: 2.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 509/509 [00:52<00:00,  9.63it/s, v_num=33, train_loss_step=2.560, train_acc_step=0.000, val_loss=2.060, val_acc=0.425, train_loss_epoch=2.150, train_acc_epoch=0.425]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.01. New best score: 2.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 509/509 [00:29<00:00, 17.07it/s, v_num=33, train_loss_step=0.438, train_acc_step=1.000, val_loss=2.040, val_acc=0.434, train_loss_epoch=2.100, train_acc_epoch=0.432] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.01. New best score: 2.043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 509/509 [00:31<00:00, 16.23it/s, v_num=33, train_loss_step=3.930, train_acc_step=0.000, val_loss=2.030, val_acc=0.445, train_loss_epoch=2.090, train_acc_epoch=0.431] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.01. New best score: 2.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 509/509 [00:29<00:00, 17.18it/s, v_num=33, train_loss_step=2.510, train_acc_step=0.000, val_loss=2.000, val_acc=0.457, train_loss_epoch=2.040, train_acc_epoch=0.437]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.027 >= min_delta = 0.01. New best score: 2.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 509/509 [00:30<00:00, 16.76it/s, v_num=33, train_loss_step=0.618, train_acc_step=1.000, val_loss=1.980, val_acc=0.463, train_loss_epoch=2.040, train_acc_epoch=0.461] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.026 >= min_delta = 0.01. New best score: 1.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 509/509 [00:30<00:00, 16.74it/s, v_num=33, train_loss_step=2.870, train_acc_step=0.000, val_loss=1.950, val_acc=0.463, train_loss_epoch=2.000, train_acc_epoch=0.462]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.01. New best score: 1.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 509/509 [00:28<00:00, 17.76it/s, v_num=33, train_loss_step=0.714, train_acc_step=1.000, val_loss=1.910, val_acc=0.478, train_loss_epoch=1.940, train_acc_epoch=0.453]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.048 >= min_delta = 0.01. New best score: 1.905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 509/509 [00:29<00:00, 17.12it/s, v_num=33, train_loss_step=2.190, train_acc_step=0.000, val_loss=1.880, val_acc=0.472, train_loss_epoch=1.920, train_acc_epoch=0.467]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.01. New best score: 1.884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 509/509 [00:27<00:00, 18.58it/s, v_num=33, train_loss_step=2.880, train_acc_step=0.000, val_loss=1.830, val_acc=0.501, train_loss_epoch=1.850, train_acc_epoch=0.488] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.051 >= min_delta = 0.01. New best score: 1.833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 509/509 [00:28<00:00, 17.63it/s, v_num=33, train_loss_step=1.370, train_acc_step=1.000, val_loss=1.820, val_acc=0.501, train_loss_epoch=1.860, train_acc_epoch=0.477] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.01. New best score: 1.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 509/509 [00:29<00:00, 17.05it/s, v_num=33, train_loss_step=2.020, train_acc_step=0.000, val_loss=1.800, val_acc=0.516, train_loss_epoch=1.830, train_acc_epoch=0.488]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.01. New best score: 1.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 509/509 [00:28<00:00, 17.56it/s, v_num=33, train_loss_step=3.910, train_acc_step=0.000, val_loss=1.770, val_acc=0.522, train_loss_epoch=1.810, train_acc_epoch=0.505]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.030 >= min_delta = 0.01. New best score: 1.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 509/509 [00:29<00:00, 17.02it/s, v_num=33, train_loss_step=2.760, train_acc_step=0.000, val_loss=1.730, val_acc=0.528, train_loss_epoch=1.750, train_acc_epoch=0.511] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.039 >= min_delta = 0.01. New best score: 1.728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 509/509 [00:29<00:00, 17.15it/s, v_num=33, train_loss_step=0.627, train_acc_step=1.000, val_loss=1.710, val_acc=0.528, train_loss_epoch=1.680, train_acc_epoch=0.543] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.01. New best score: 1.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 509/509 [00:28<00:00, 17.83it/s, v_num=33, train_loss_step=3.270, train_acc_step=0.000, val_loss=1.680, val_acc=0.534, train_loss_epoch=1.680, train_acc_epoch=0.527]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.01. New best score: 1.685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 509/509 [00:29<00:00, 17.08it/s, v_num=33, train_loss_step=2.070, train_acc_step=1.000, val_loss=1.650, val_acc=0.543, train_loss_epoch=1.650, train_acc_epoch=0.551] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.033 >= min_delta = 0.01. New best score: 1.652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 509/509 [00:30<00:00, 16.95it/s, v_num=33, train_loss_step=2.150, train_acc_step=0.000, val_loss=1.620, val_acc=0.558, train_loss_epoch=1.640, train_acc_epoch=0.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.029 >= min_delta = 0.01. New best score: 1.624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 509/509 [00:29<00:00, 17.38it/s, v_num=33, train_loss_step=1.350, train_acc_step=1.000, val_loss=1.610, val_acc=0.558, train_loss_epoch=1.600, train_acc_epoch=0.566]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.01. New best score: 1.607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 509/509 [00:55<00:00,  9.18it/s, v_num=33, train_loss_step=1.400, train_acc_step=0.000, val_loss=1.570, val_acc=0.575, train_loss_epoch=1.540, train_acc_epoch=0.572] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.039 >= min_delta = 0.01. New best score: 1.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 509/509 [01:11<00:00,  7.10it/s, v_num=33, train_loss_step=0.778, train_acc_step=1.000, val_loss=1.550, val_acc=0.572, train_loss_epoch=1.510, train_acc_epoch=0.589] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.01. New best score: 1.553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 509/509 [00:49<00:00, 10.20it/s, v_num=33, train_loss_step=0.735, train_acc_step=1.000, val_loss=1.530, val_acc=0.572, train_loss_epoch=1.490, train_acc_epoch=0.592] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.01. New best score: 1.533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 509/509 [00:45<00:00, 11.08it/s, v_num=33, train_loss_step=0.112, train_acc_step=1.000, val_loss=1.520, val_acc=0.584, train_loss_epoch=1.460, train_acc_epoch=0.591]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.01. New best score: 1.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 509/509 [00:29<00:00, 17.22it/s, v_num=33, train_loss_step=0.294, train_acc_step=1.000, val_loss=1.490, val_acc=0.578, train_loss_epoch=1.440, train_acc_epoch=0.592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.01. New best score: 1.490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 509/509 [00:29<00:00, 17.48it/s, v_num=33, train_loss_step=0.585, train_acc_step=1.000, val_loss=1.470, val_acc=0.593, train_loss_epoch=1.410, train_acc_epoch=0.605]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.01. New best score: 1.471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 509/509 [00:29<00:00, 17.21it/s, v_num=33, train_loss_step=2.460, train_acc_step=0.000, val_loss=1.430, val_acc=0.593, train_loss_epoch=1.360, train_acc_epoch=0.624] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.043 >= min_delta = 0.01. New best score: 1.428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 509/509 [00:30<00:00, 16.71it/s, v_num=33, train_loss_step=0.442, train_acc_step=1.000, val_loss=1.410, val_acc=0.599, train_loss_epoch=1.330, train_acc_epoch=0.641] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.01. New best score: 1.414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 509/509 [00:28<00:00, 17.61it/s, v_num=33, train_loss_step=1.440, train_acc_step=1.000, val_loss=1.400, val_acc=0.599, train_loss_epoch=1.290, train_acc_epoch=0.654] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.01. New best score: 1.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 509/509 [00:29<00:00, 17.06it/s, v_num=33, train_loss_step=0.717, train_acc_step=1.000, val_loss=1.370, val_acc=0.590, train_loss_epoch=1.230, train_acc_epoch=0.661] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.025 >= min_delta = 0.01. New best score: 1.374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 509/509 [00:29<00:00, 17.35it/s, v_num=33, train_loss_step=0.851, train_acc_step=1.000, val_loss=1.340, val_acc=0.619, train_loss_epoch=1.210, train_acc_epoch=0.646] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.01. New best score: 1.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 509/509 [00:40<00:00, 12.71it/s, v_num=33, train_loss_step=2.330, train_acc_step=0.000, val_loss=1.320, val_acc=0.619, train_loss_epoch=1.220, train_acc_epoch=0.660] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.01. New best score: 1.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 509/509 [00:49<00:00, 10.38it/s, v_num=33, train_loss_step=0.953, train_acc_step=1.000, val_loss=1.300, val_acc=0.625, train_loss_epoch=1.180, train_acc_epoch=0.677]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.01. New best score: 1.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 509/509 [00:30<00:00, 16.85it/s, v_num=33, train_loss_step=1.310, train_acc_step=1.000, val_loss=1.280, val_acc=0.640, train_loss_epoch=1.130, train_acc_epoch=0.667] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.01. New best score: 1.280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 509/509 [00:47<00:00, 10.82it/s, v_num=33, train_loss_step=2.080, train_acc_step=0.000, val_loss=1.270, val_acc=0.652, train_loss_epoch=1.120, train_acc_epoch=0.695] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.01. New best score: 1.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 509/509 [00:55<00:00,  9.18it/s, v_num=33, train_loss_step=0.840, train_acc_step=1.000, val_loss=1.250, val_acc=0.646, train_loss_epoch=1.100, train_acc_epoch=0.684] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.01. New best score: 1.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101: 100%|██████████| 509/509 [00:28<00:00, 17.55it/s, v_num=33, train_loss_step=0.958, train_acc_step=1.000, val_loss=1.230, val_acc=0.652, train_loss_epoch=1.030, train_acc_epoch=0.712] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.01. New best score: 1.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102: 100%|██████████| 509/509 [00:29<00:00, 17.42it/s, v_num=33, train_loss_step=0.184, train_acc_step=1.000, val_loss=1.220, val_acc=0.664, train_loss_epoch=1.020, train_acc_epoch=0.713] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.01. New best score: 1.219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106: 100%|██████████| 509/509 [00:30<00:00, 16.71it/s, v_num=33, train_loss_step=0.115, train_acc_step=1.000, val_loss=1.200, val_acc=0.652, train_loss_epoch=0.978, train_acc_epoch=0.730] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.01. New best score: 1.201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108: 100%|██████████| 509/509 [00:32<00:00, 15.64it/s, v_num=33, train_loss_step=0.515, train_acc_step=1.000, val_loss=1.190, val_acc=0.661, train_loss_epoch=0.962, train_acc_epoch=0.735] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.01. New best score: 1.190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109: 100%|██████████| 509/509 [00:31<00:00, 16.11it/s, v_num=33, train_loss_step=0.913, train_acc_step=1.000, val_loss=1.170, val_acc=0.655, train_loss_epoch=0.953, train_acc_epoch=0.727] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.01. New best score: 1.175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111: 100%|██████████| 509/509 [00:32<00:00, 15.75it/s, v_num=33, train_loss_step=0.313, train_acc_step=1.000, val_loss=1.160, val_acc=0.684, train_loss_epoch=0.936, train_acc_epoch=0.744] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.01. New best score: 1.160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116: 100%|██████████| 509/509 [00:31<00:00, 16.25it/s, v_num=33, train_loss_step=0.230, train_acc_step=1.000, val_loss=1.140, val_acc=0.690, train_loss_epoch=0.853, train_acc_epoch=0.746]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.01. New best score: 1.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117: 100%|██████████| 509/509 [00:36<00:00, 13.87it/s, v_num=33, train_loss_step=0.134, train_acc_step=1.000, val_loss=1.130, val_acc=0.702, train_loss_epoch=0.853, train_acc_epoch=0.759] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.01. New best score: 1.128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: 100%|██████████| 509/509 [00:32<00:00, 15.45it/s, v_num=33, train_loss_step=0.227, train_acc_step=1.000, val_loss=1.110, val_acc=0.717, train_loss_epoch=0.830, train_acc_epoch=0.766] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.01. New best score: 1.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: 100%|██████████| 509/509 [00:34<00:00, 14.56it/s, v_num=33, train_loss_step=0.993, train_acc_step=1.000, val_loss=1.090, val_acc=0.714, train_loss_epoch=0.767, train_acc_epoch=0.794]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.01. New best score: 1.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128: 100%|██████████| 509/509 [00:30<00:00, 16.57it/s, v_num=33, train_loss_step=0.416, train_acc_step=1.000, val_loss=1.080, val_acc=0.723, train_loss_epoch=0.760, train_acc_epoch=0.794] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.01. New best score: 1.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133: 100%|██████████| 509/509 [00:37<00:00, 13.72it/s, v_num=33, train_loss_step=0.695, train_acc_step=1.000, val_loss=1.060, val_acc=0.732, train_loss_epoch=0.699, train_acc_epoch=0.809] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.01. New best score: 1.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136: 100%|██████████| 509/509 [00:32<00:00, 15.53it/s, v_num=33, train_loss_step=0.0896, train_acc_step=1.000, val_loss=1.040, val_acc=0.735, train_loss_epoch=0.701, train_acc_epoch=0.805]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.01. New best score: 1.042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140: 100%|██████████| 509/509 [00:34<00:00, 14.96it/s, v_num=33, train_loss_step=0.905, train_acc_step=1.000, val_loss=1.030, val_acc=0.720, train_loss_epoch=0.648, train_acc_epoch=0.818] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.01. New best score: 1.031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142: 100%|██████████| 509/509 [00:35<00:00, 14.20it/s, v_num=33, train_loss_step=0.574, train_acc_step=1.000, val_loss=1.010, val_acc=0.743, train_loss_epoch=0.642, train_acc_epoch=0.819] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.01. New best score: 1.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147: 100%|██████████| 509/509 [00:30<00:00, 16.95it/s, v_num=33, train_loss_step=0.0457, train_acc_step=1.000, val_loss=1.000, val_acc=0.746, train_loss_epoch=0.616, train_acc_epoch=0.829]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.01. New best score: 1.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151: 100%|██████████| 509/509 [00:32<00:00, 15.55it/s, v_num=33, train_loss_step=0.0524, train_acc_step=1.000, val_loss=0.987, val_acc=0.743, train_loss_epoch=0.603, train_acc_epoch=0.839]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.01. New best score: 0.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157: 100%|██████████| 509/509 [00:31<00:00, 16.03it/s, v_num=33, train_loss_step=0.999, train_acc_step=1.000, val_loss=0.972, val_acc=0.752, train_loss_epoch=0.537, train_acc_epoch=0.852]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.01. New best score: 0.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166: 100%|██████████| 509/509 [00:31<00:00, 15.97it/s, v_num=33, train_loss_step=3.010, train_acc_step=0.000, val_loss=0.961, val_acc=0.746, train_loss_epoch=0.488, train_acc_epoch=0.871]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.01. New best score: 0.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176: 100%|██████████| 509/509 [00:34<00:00, 14.92it/s, v_num=33, train_loss_step=0.082, train_acc_step=1.000, val_loss=0.990, val_acc=0.735, train_loss_epoch=0.425, train_acc_epoch=0.892]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.961. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176: 100%|██████████| 509/509 [00:35<00:00, 14.15it/s, v_num=33, train_loss_step=0.082, train_acc_step=1.000, val_loss=0.990, val_acc=0.735, train_loss_epoch=0.425, train_acc_epoch=0.892]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\yohanes.setiawan\\AppData\\Local\\miniconda3\\envs\\wmmd_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 170/170 [00:10<00:00, 15.80it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.7109144330024719\n",
      "         test_f1            0.6509345173835754\n",
      "        test_loss           1.0668379068374634\n",
      "     test_precision         0.7045230865478516\n",
      "       test_recall          0.6248770952224731\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Artifacts saved to model\\mae-ast_imbalance\\20250702_170155/\n",
      "Completed mae-ast (FT), artifacts in model\\mae-ast_imbalance\\20250702_170155\n"
     ]
    }
   ],
   "source": [
    "# training Loops\n",
    "for cfg in model_configs:\n",
    "    dm = WMMDDataModule(\n",
    "        dataset_dict=ds,\n",
    "        backbone=cfg[\"backbone\"],\n",
    "        batch_size=2,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    model = WMMDClassifier(\n",
    "        num_classes=cfg['num_classes'], lr=cfg['lr'],\n",
    "        backbone=cfg['backbone'], finetune=cfg['finetune'],\n",
    "        class_weights=cfg['class_weights'], \n",
    "        ckpt_path=cfg['ckpt_path']\n",
    "    )\n",
    "    metrics_cb = MetricsLogger()\n",
    "    callbacks = [metrics_cb, early_stopping]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "        accelerator='gpu', devices=1,\n",
    "        precision='16-mixed', accumulate_grad_batches=2,\n",
    "        check_val_every_n_epoch=1,\n",
    "        num_sanity_val_steps=0,\n",
    "        enable_progress_bar=True, log_every_n_steps=1,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, dm)\n",
    "    test_res = trainer.test(model, dm)[0]\n",
    "\n",
    "    model.test_results = test_res\n",
    "    model.finish_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model.epochs_trained = trainer.current_epoch + 1\n",
    "    model.save_model()\n",
    "\n",
    "    metrics_map = {\n",
    "        'accuracy':   ('train_accs',      'val_accs'),\n",
    "        'precision':  ('train_precisions','val_precisions'),\n",
    "        'recall':     ('train_recalls',   'val_recalls'),\n",
    "        'f1_score':   ('train_f1s',       'val_f1s'),\n",
    "    }\n",
    "    \n",
    "    for metric_name, (train_attr, val_attr) in metrics_map.items():\n",
    "        train_vals = getattr(metrics_cb, train_attr)\n",
    "        val_vals = getattr(metrics_cb, val_attr)\n",
    "        epochs = list(range(1, len(train_vals) + 1))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, train_vals, label=f'train_{metric_name}')\n",
    "        plt.plot(epochs, val_vals,   label=f'val_{metric_name}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric_name.replace('_', ' ').title())\n",
    "        plt.title(f\"{metric_name.replace('_', ' ').title()} over Epochs {model._last_timestamp}\")\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plot_file = os.path.join(model._last_save_dir, f\"{model._last_timestamp}_{metric_name}.png\")\n",
    "        plt.savefig(plot_file)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Completed {cfg['backbone']} ({'FT' if cfg['finetune'] else 'Frozen'}), artifacts in {model._last_save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
